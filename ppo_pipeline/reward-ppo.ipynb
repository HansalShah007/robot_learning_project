{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla PPO + action wrapper + reward shaping\n",
    "\n",
    "Run on 3 environments\n",
    "\n",
    "Empty Room\n",
    "\n",
    "Empty Room Random\n",
    "\n",
    "Four Rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import minigrid\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from minigrid.wrappers import FlatObsWrapper\n",
    "import time\n",
    "import numpy as np\n",
    "from minigrid.core.world_object import Goal\n",
    "import random\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from gymnasium.envs.registration import register\n",
    "from minigrid.core.constants import OBJECT_TO_IDX, IDX_TO_OBJECT, COLOR_TO_IDX, IDX_TO_COLOR, DIR_TO_VEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and wrap the environment\n",
    "env_id = \"MiniGrid-Empty-16x16-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ActionWrapper, self).__init__(env)\n",
    "        # Define a new action space with only the relevant actions\n",
    "        self.action_space = gym.spaces.Discrete(3)  # Only three actions: left, right, forward\n",
    "\n",
    "    def action(self, action):\n",
    "        # Map the new actions to the original actions\n",
    "        action_mapping = {\n",
    "            0: 0,  # left\n",
    "            1: 1,  # right\n",
    "            2: 2   # forward\n",
    "        }\n",
    "        return action_mapping[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardShapingWrapper1(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(RewardShapingWrapper1, self).__init__(env)\n",
    "        self.last_action = None\n",
    "        self.spin_counter = 0  # Tracks consecutive left-right turns\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info, extra = self.env.step(action)\n",
    "        current_pos = self.env.agent_pos\n",
    "\n",
    "        # Check for spinning behavior\n",
    "        if self.last_action in [0, 1] and action in [0, 1] and action != self.last_action:\n",
    "            self.spin_counter += 1\n",
    "        else:\n",
    "            self.spin_counter = 0\n",
    "\n",
    "        if self.spin_counter > 2:  # Threshold for considering it spinning\n",
    "            reward -= 10\n",
    "            self.spin_counter = 0  # Reset counter after penalty\n",
    "\n",
    "        if self.last_action == 0 and action == 1 or self.last_action == 1 and action == 0:\n",
    "            reward -= 10  # Increase penalty for oscillating between left and right\n",
    "\n",
    "        self.last_action = action\n",
    "        return obs, reward, done, info, extra\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        self.last_action = None\n",
    "        self.spin_counter = 0\n",
    "        return obs\n",
    "\n",
    "    def is_facing_wall(self):\n",
    "        x, y = self.env.agent_pos\n",
    "        direction_idx = self.env.agent_dir\n",
    "        delta = self.env.DIR_TO_VEC[direction_idx]\n",
    "        next_x, next_y = x + delta[0], y + delta[1]\n",
    "        if 0 <= next_x < self.env.width and 0 <= next_y < self.env.height:\n",
    "            next_cell = self.env.grid.get(next_x, next_y)\n",
    "            return next_cell is not None and next_cell.type == 'wall'\n",
    "        return False\n",
    "    \n",
    "    def get_goal_position(self):\n",
    "        for x in range(self.env.width):\n",
    "            for y in range(self.env.height):\n",
    "                if self.env.grid.get(x, y) is not None and isinstance(self.env.grid.get(x, y), Goal):\n",
    "                    return (x, y)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardShapingWrapper2(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.last_room_id = None\n",
    "        self.goal_position = None\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        self.last_room_id = self.get_room_id(obs)\n",
    "        self.goal_position = self.find_goal_position()\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        current_room_id = self.get_room_id(obs)\n",
    "        agent_pos = self.env.agent_pos\n",
    "\n",
    "        # Check if the agent has passed through a doorway\n",
    "        if current_room_id != self.last_room_id:\n",
    "            reward += 0.1  \n",
    "            self.last_room_id = current_room_id\n",
    "\n",
    "        # Check if the goal is reached by comparing positions\n",
    "        if tuple(agent_pos) == self.goal_position:\n",
    "            reward += 100 \n",
    "            terminated = True  \n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def get_room_id(self, obs):\n",
    "        # Implement logic to determine the room ID based on the agent's position\n",
    "        agent_pos = self.env.agent_pos\n",
    "        if agent_pos[0] < self.env.width // 2:\n",
    "            if agent_pos[1] < self.env.height // 2:\n",
    "                return 0  \n",
    "            else:\n",
    "                return 2  \n",
    "        else:\n",
    "            if agent_pos[1] < self.env.height // 2:\n",
    "                return 1  \n",
    "            else:\n",
    "                return 3  \n",
    "\n",
    "    def find_goal_position(self):\n",
    "        # Scan the grid to find the goal's position\n",
    "        for x in range(self.env.width):\n",
    "            for y in range(self.env.height):\n",
    "                if isinstance(self.env.grid.get(x, y), Goal):\n",
    "                    return (x, y)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardShapingWrapper3(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(RewardShapingWrapper3, self).__init__(env)\n",
    "        self.last_pos = None\n",
    "        self.goal_pos = None\n",
    "        self.stuck_counter = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        action = self.noisy_action(action)  # Apply noise to the action for exploration\n",
    "        obs, reward, done, info, extra = self.env.step(action)\n",
    "        current_pos = self.env.agent_pos\n",
    "\n",
    "        if self.goal_pos is None:\n",
    "            self.goal_pos = self.get_goal_position()\n",
    "\n",
    "        current_room = self.get_room(current_pos)\n",
    "        last_room = self.get_room(self.last_pos) if self.last_pos else None\n",
    "\n",
    "        # Check if transitioned to a new room\n",
    "        if last_room and current_room and last_room != current_room:\n",
    "            reward += 5.0  # Reward for moving to a new room\n",
    "\n",
    "        # Additional vector to the nearest gap or doorway\n",
    "        nearest_gap_vector = self.get_vector_to_nearest_gap(current_pos)\n",
    "        obs['nearest_gap_direction'] = nearest_gap_vector  # Ensure obs is a dictionary\n",
    "\n",
    "        # Assuming obs is a dictionary that includes 'image' and possibly other keys\n",
    "        goal_direction = self.get_goal_direction(current_pos)\n",
    "        # If you intend to add goal_direction to obs, you should add it as a new key-value pair\n",
    "        obs['goal_direction'] = goal_direction  # Add it like this if obs is a dictionary\n",
    "\n",
    "        # Reward shaping calculations\n",
    "        if self.last_pos is not None and self.goal_pos is not None:\n",
    "            distance_reward = self.calculate_reward_shaping(current_pos)\n",
    "            additional_reward = self.additional_rewards(action, current_pos, self.last_pos)\n",
    "            reward += distance_reward + additional_reward\n",
    "\n",
    "        if np.array_equal(current_pos, self.goal_pos):\n",
    "            reward += 100\n",
    "            done = True\n",
    "\n",
    "        if self.last_pos == current_pos:\n",
    "            self.stuck_counter += 1\n",
    "        else:\n",
    "            self.stuck_counter = 0\n",
    "\n",
    "        if self.stuck_counter > 3:\n",
    "            obs = self.nudge_agent(current_pos) or obs\n",
    "            self.stuck_counter = 0\n",
    "\n",
    "        self.last_pos = current_pos\n",
    "        return obs, reward, done, info, extra\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        self.last_pos = self.env.agent_pos\n",
    "        self.goal_pos = self.get_goal_position()\n",
    "        self.gaps = self.find_gaps()  # Find gaps upon reset\n",
    "        return obs\n",
    "    \n",
    "    def get_vector_to_nearest_gap(self, current_pos):\n",
    "        if not self.gaps:\n",
    "            return np.zeros(2)  # Default to zero vector if no gaps identified\n",
    "\n",
    "        nearest_gap = min(self.gaps, key=lambda gap: np.linalg.norm(np.array(gap) - np.array(current_pos)))\n",
    "        direction_vector = np.array(nearest_gap) - np.array(current_pos)\n",
    "        norm = np.linalg.norm(direction_vector)\n",
    "        return direction_vector / norm if norm != 0 else direction_vector\n",
    "\n",
    "    \n",
    "    def find_gaps(self):\n",
    "        width, height = self.env.width, self.env.height\n",
    "        gaps = []\n",
    "        # Typically, gaps will be in the walls that divide the rooms\n",
    "        # We scan horizontal and vertical mid-lines for empty spaces\n",
    "        mid_vertical = width // 2\n",
    "        mid_horizontal = height // 2\n",
    "\n",
    "        # Vertical mid-line (check for empty cells)\n",
    "        for y in range(height):\n",
    "            if self.env.grid.get(mid_vertical, y) is None:\n",
    "                #print('vertical', self.env.grid.get(mid_vertical, y))\n",
    "                #print('the gap vertical mid-line is',(mid_vertical, y) )\n",
    "                gaps.append((mid_vertical, y))\n",
    "\n",
    "        # Horizontal mid-line (check for empty cells)\n",
    "        for x in range(width):\n",
    "            if self.env.grid.get(x, mid_horizontal) is None:\n",
    "                gaps.append((x, mid_horizontal))\n",
    "\n",
    "        return gaps\n",
    "\n",
    "\n",
    "    def get_goal_position(self):\n",
    "        for x in range(self.env.width):\n",
    "            for y in range(self.env.height):\n",
    "                if self.env.grid.get(x, y) is not None and isinstance(self.env.grid.get(x, y), Goal):\n",
    "                    return (x, y)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def calculate_reward_shaping(self, current_pos):\n",
    "        if not self.goal_pos:\n",
    "            return 0\n",
    "        \n",
    "        epsilon = 0.01  # Small value to avoid division by zero\n",
    "        prev_distance = np.linalg.norm(np.array(self.last_pos) - np.array(self.goal_pos))\n",
    "        current_distance = np.linalg.norm(np.array(current_pos) - np.array(self.goal_pos))\n",
    "        \n",
    "        if current_distance < prev_distance:\n",
    "            return 0.1 * (1 / (current_distance + epsilon))\n",
    "        elif current_distance > prev_distance:\n",
    "            return -0.1 * (1 / (current_distance + epsilon))\n",
    "        return 0\n",
    "\n",
    "    def additional_rewards(self, action, current_pos, prev_pos):\n",
    "        prev_distance = np.linalg.norm(np.array(prev_pos) - np.array(self.goal_pos))\n",
    "        current_distance = np.linalg.norm(np.array(current_pos) - np.array(self.goal_pos))\n",
    "        distance_change = prev_distance - current_distance\n",
    "        \n",
    "        if action in [0, 1] and distance_change <= 0:\n",
    "            return -0.05  # Unchanged, penalty for non-improvement\n",
    "        \n",
    "        reward = 0\n",
    "        if action == 2 and distance_change > 0:\n",
    "            reward = min(0.05 * distance_change, 1.0)  # Cap the reward to avoid excessively high values\n",
    "\n",
    "        return reward\n",
    "    \n",
    "\n",
    "    def get_goal_direction(self, current_pos):\n",
    "        if not self.goal_pos:\n",
    "            return np.zeros_like(current_pos)  # Return a zero vector if goal position is not set\n",
    "        # Assuming current_pos and goal_pos are numpy arrays or can be converted to them\n",
    "        direction_vector = np.array(self.goal_pos) - np.array(current_pos)\n",
    "        # Normalize the vector\n",
    "        norm = np.linalg.norm(direction_vector)\n",
    "        if norm == 0:\n",
    "            return direction_vector  # Avoid division by zero if already at the goal\n",
    "        return direction_vector / norm\n",
    "    \n",
    "    def noisy_action(self, action):\n",
    "        # Add random noise to the action occasionally\n",
    "        if random.random() < 0.1:  # With 10% probability, alter the action randomly\n",
    "            return random.choice([0, 1, 2])  # Assuming actions are 0, 1, 2\n",
    "        return action\n",
    "    \n",
    "\n",
    "    def get_possible_moves(self, current_pos):\n",
    "        moves = []\n",
    "        directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # Directions: up, down, left, right\n",
    "\n",
    "        for dx, dy in directions:\n",
    "            new_pos = (current_pos[0] + dx, current_pos[1] + dy)\n",
    "            if self.is_position_valid(new_pos):\n",
    "                moves.append(new_pos)\n",
    "        return moves\n",
    "\n",
    "    def is_position_valid(self, pos):\n",
    "        x, y = pos\n",
    "        # Check if within grid bounds\n",
    "        if 0 <= x < self.env.width and 0 <= y < self.env.height:\n",
    "            # Check if the cell is empty (None means empty in MiniGrid)\n",
    "            return self.env.grid.get(x, y) is None\n",
    "        return False\n",
    "    \n",
    "    def nudge_agent(self, current_pos):\n",
    "        possible_moves = self.get_possible_moves(current_pos)\n",
    "        if possible_moves:\n",
    "            new_pos = random.choice(possible_moves)\n",
    "            self.env.agent_pos = new_pos  # Assuming you can set the position\n",
    "            # Simulate a no-op or a neutral action to update state and get observation\n",
    "            obs, _, _, _, _ = self.env.step(0)  # Consider '0' as a no-op action, if applicable\n",
    "            return obs\n",
    "        # If no moves are possible or other issues arise, return a default observation\n",
    "        return np.zeros(self.env.observation_space.shape)  # Adjust based on the specific obs space\n",
    "    \n",
    "    def get_room(self, position):\n",
    "        x, y = position\n",
    "        if x < 10 and y < 10:\n",
    "            return 1  # Top-left room\n",
    "        elif x >= 10 and y < 10:\n",
    "            return 2  # Top-right room\n",
    "        elif x < 10 and y >= 10:\n",
    "            return 3  # Bottom-left room\n",
    "        elif x >= 10 and y >= 10:\n",
    "            return 4  # Bottom-right room\n",
    "        return 0  # Should not happen unless position is out of expected range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env():\n",
    "    env = gym.make(env_id, render_mode=\"rgb_array\")#,max_episode_steps=200)\n",
    "    env = ActionWrapper(env)\n",
    "    env = RewardShapingWrapper1(env)\n",
    "    env = FlatObsWrapper(env)  \n",
    "    return env\n",
    "\n",
    "# Use the function in make_vec_env\n",
    "env_vec = make_vec_env(create_env, n_envs=1)\n",
    "env_vec2 = make_vec_env(create_env, n_envs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to log/ppo_reward_empty_no_step_cap/PPO_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthony/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 841       |\n",
      "|    ep_rew_mean     | -2.07e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 5062      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 1         |\n",
      "|    total_timesteps | 8192      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 785         |\n",
      "|    ep_rew_mean          | -1.68e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2554        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012359096 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.000418    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 799         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 719         |\n",
      "|    ep_rew_mean          | -1.34e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2181        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017319087 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -1.87e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 381         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 687        |\n",
      "|    ep_rew_mean          | -1.09e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2113       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01946026 |\n",
      "|    clip_fraction        | 0.35       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.954     |\n",
      "|    explained_variance   | -2.38e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 128        |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0327    |\n",
      "|    value_loss           | 172        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 581         |\n",
      "|    ep_rew_mean          | -795        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2074        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017089937 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | -1.07e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 473         |\n",
      "|    ep_rew_mean          | -559        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2048        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011101613 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | -8.34e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 357         |\n",
      "|    ep_rew_mean          | -190        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2032        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008130961 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.652      |\n",
      "|    explained_variance   | -1.55e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.6        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 263         |\n",
      "|    ep_rew_mean          | -68.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2016        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006506634 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.556      |\n",
      "|    explained_variance   | 0.0778      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    value_loss           | 76.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 216          |\n",
      "|    ep_rew_mean          | -26.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2008         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047019776 |\n",
      "|    clip_fraction        | 0.074        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.4         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    value_loss           | 66.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 183          |\n",
      "|    ep_rew_mean          | -13.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2003         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035239148 |\n",
      "|    clip_fraction        | 0.0536       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28.3         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 143         |\n",
      "|    ep_rew_mean          | -5.33       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1997        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004946853 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.385      |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 101         |\n",
      "|    ep_rew_mean          | -0.989      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1990        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003993181 |\n",
      "|    clip_fraction        | 0.0373      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68.1         |\n",
      "|    ep_rew_mean          | 0.34         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1985         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021503912 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.269       |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.71         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49           |\n",
      "|    ep_rew_mean          | 0.857        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1981         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020835204 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.219       |\n",
      "|    explained_variance   | 0.316        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.26         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    value_loss           | 11.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 47.2         |\n",
      "|    ep_rew_mean          | 0.858        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1979         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027575584 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.18        |\n",
      "|    explained_variance   | 0.319        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    value_loss           | 4.87         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 46.2         |\n",
      "|    ep_rew_mean          | 0.859        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1978         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014076652 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.15        |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.879        |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40.8         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1978         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018246463 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.155       |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.291        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    value_loss           | 0.752        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36           |\n",
      "|    ep_rew_mean          | 0.868        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1977         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071927905 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.128       |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.157        |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    value_loss           | 0.198        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | 0.973        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1977         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014695169 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.108       |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0249       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 0.148        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 46.3         |\n",
      "|    ep_rew_mean          | 0.959        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1971         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024399995 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.11        |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00486      |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 0.021        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34.2         |\n",
      "|    ep_rew_mean          | 0.97         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1969         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014406126 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.112       |\n",
      "|    explained_variance   | 0.0363       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00916      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    value_loss           | 0.022        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1969        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012340913 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0782     |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00628    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 0.0107      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.3         |\n",
      "|    ep_rew_mean          | 0.974        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1969         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016549168 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0707      |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00429     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 0.0533       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.9         |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1969         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017351996 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0562      |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000159     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    value_loss           | 0.00343      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 52.7         |\n",
      "|    ep_rew_mean          | 0.954        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1966         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034462933 |\n",
      "|    clip_fraction        | 0.0818       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0599      |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000835    |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 0.00259      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x32d86b2e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env_vec2, verbose=1,\n",
    "            tensorboard_log=\"log/ppo_reward_empty_no_step_cap\"\n",
    "            )\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/ppo_reward_empty_no_step_cap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward: 0.9762699999999999 +/- 1.1102230246251565e-16\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"models/ppo_reward_empty_no_step_cap\",env=env_vec)\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env=env_vec, n_eval_episodes=50)\n",
    "print(f\"Mean Reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = [0.97626954]\n",
      "Episode 2: Total Reward = [0.97626954]\n",
      "Episode 3: Total Reward = [0.97626954]\n",
      "Episode 4: Total Reward = [0.97626954]\n",
      "Episode 5: Total Reward = [0.97626954]\n",
      "Episode 6: Total Reward = [0.97626954]\n",
      "Episode 7: Total Reward = [0.97626954]\n",
      "Episode 8: Total Reward = [0.97626954]\n",
      "Episode 9: Total Reward = [0.97626954]\n",
      "Episode 10: Total Reward = [0.97626954]\n",
      "Episode 11: Total Reward = [0.97626954]\n",
      "Episode 12: Total Reward = [0.97626954]\n",
      "Episode 13: Total Reward = [0.97626954]\n",
      "Episode 14: Total Reward = [0.9753906]\n",
      "Episode 15: Total Reward = [0.9753906]\n",
      "Episode 16: Total Reward = [0.97451174]\n",
      "Episode 17: Total Reward = [0.97626954]\n",
      "Episode 18: Total Reward = [0.97626954]\n",
      "Episode 19: Total Reward = [0.97626954]\n",
      "Episode 20: Total Reward = [0.9753906]\n",
      "Episode 21: Total Reward = [0.97626954]\n",
      "Episode 22: Total Reward = [0.97626954]\n",
      "Episode 23: Total Reward = [0.97626954]\n",
      "Episode 24: Total Reward = [0.9753906]\n",
      "Episode 25: Total Reward = [0.97626954]\n",
      "Episode 26: Total Reward = [0.97626954]\n",
      "Episode 27: Total Reward = [0.97626954]\n",
      "Episode 28: Total Reward = [0.97626954]\n",
      "Episode 29: Total Reward = [0.9753906]\n",
      "Episode 30: Total Reward = [0.97626954]\n",
      "Episode 31: Total Reward = [0.97626954]\n",
      "Episode 32: Total Reward = [0.97451174]\n",
      "Episode 33: Total Reward = [0.97626954]\n",
      "Episode 34: Total Reward = [0.9727539]\n",
      "Episode 35: Total Reward = [0.9753906]\n",
      "Episode 36: Total Reward = [0.97626954]\n",
      "Episode 37: Total Reward = [0.97626954]\n",
      "Episode 38: Total Reward = [0.9753906]\n",
      "Episode 39: Total Reward = [0.97626954]\n",
      "Episode 40: Total Reward = [0.97626954]\n",
      "Episode 41: Total Reward = [0.9753906]\n",
      "Episode 42: Total Reward = [0.97626954]\n",
      "Episode 43: Total Reward = [0.97626954]\n",
      "Episode 44: Total Reward = [0.97626954]\n",
      "Episode 45: Total Reward = [0.9753906]\n",
      "Episode 46: Total Reward = [0.97626954]\n",
      "Episode 47: Total Reward = [0.97626954]\n",
      "Episode 48: Total Reward = [0.97626954]\n",
      "Episode 49: Total Reward = [0.9753906]\n",
      "Episode 50: Total Reward = [0.97626954]\n",
      "Average Reward over 50 episodes: [0.975953]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "total_rewards = []  # List to store total rewards for each episode\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs = env_vec.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env_vec.step(action)\n",
    "        #print(done)\n",
    "        total_reward += reward\n",
    "        env_vec.render('human')  # Render the environment at each step\n",
    "        #time.sleep(0.05)  # Adjust this to control the speed of the rendering\n",
    "    total_rewards.append(total_reward)  # Store the total reward for this episode\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "# Calculate the average reward across all episodes\n",
    "average_reward = sum(total_rewards) / num_episodes\n",
    "print(f\"Average Reward over {num_episodes} episodes: {average_reward}\")\n",
    "\n",
    "env_vec.close()  # Close the environment when done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empty random room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthony/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment custom_empty-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "register(\n",
    "    id='custom_empty-v0',\n",
    "    entry_point='emptyrandom:RandomGoalEmptyEnv',\n",
    "    kwargs={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 'custom_empty-v0' is registered.\n"
     ]
    }
   ],
   "source": [
    "#gym.pprint_registry()  # to see all registered environments\n",
    "\n",
    "if 'custom_empty-v0' in gym.envs.registry:\n",
    "    print(\"Environment 'custom_empty-v0' is registered.\")\n",
    "else:\n",
    "    print(\"Environment 'custom_empty-v0' is NOT registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id2 = 'custom_empty-v0'\n",
    "def create_env():\n",
    "    env = gym.make(env_id2, render_mode=\"rgb_array\",size=16)#,max_episode_steps=200)\n",
    "    env = ActionWrapper(env)\n",
    "    env = RewardShapingWrapper2(env)\n",
    "    env = FlatObsWrapper(env)  \n",
    "    return env\n",
    "\n",
    "env_vec_ran = make_vec_env(create_env, n_envs=1)\n",
    "env_vec_ran2 = make_vec_env(create_env, n_envs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to log/ppo_reward_empty_random_no_step_cap/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 518      |\n",
      "|    ep_rew_mean     | 78.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 4858     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 575         |\n",
      "|    ep_rew_mean          | 77.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2892        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008512385 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.00337     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    value_loss           | 98.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 491         |\n",
      "|    ep_rew_mean          | 79.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2544        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011191473 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.0727      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.32        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    value_loss           | 85.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 502         |\n",
      "|    ep_rew_mean          | 75.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2408        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006013791 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 403         |\n",
      "|    ep_rew_mean          | 83.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2335        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008586368 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.3        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    value_loss           | 91.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 286          |\n",
      "|    ep_rew_mean          | 89.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2288         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072107418 |\n",
      "|    clip_fraction        | 0.0767       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.214        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    value_loss           | 262          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | 96.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2253         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084372815 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.287        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 67.7         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | 98.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2226        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007907063 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.8        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 85          |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2206        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011261343 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.978      |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 90.1        |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2190        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011446057 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.921      |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    value_loss           | 323         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.1        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2177        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010852391 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.925      |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.2        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2164        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012573309 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 181         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.9        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2151        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011557829 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.834      |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.2        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2141        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010578996 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.785      |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.4         |\n",
      "|    ep_rew_mean          | 101          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2132         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098215835 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.709       |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 78.2         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000717    |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2125        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016252263 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94.5        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.000606    |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.8        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2120        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011399558 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.632      |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.1        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00107    |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2114        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011931731 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.655      |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.000962    |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27          |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2108        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011106366 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.1        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.000549    |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.1        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2102        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008824762 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.7        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.000194   |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.7        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2098        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008627767 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.465      |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.4        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.000319    |\n",
      "|    value_loss           | 82.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 26.1         |\n",
      "|    ep_rew_mean          | 101          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2093         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112912655 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | 0.000812     |\n",
      "|    value_loss           | 64.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.2        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2087        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011374939 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.403      |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | 0.000994    |\n",
      "|    value_loss           | 53.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.3        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2081        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008300068 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.6        |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2077        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008203521 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.367      |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.000118   |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x348927040>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initialize the PPO model\n",
    "model2 = PPO(\"MlpPolicy\", env_vec_ran2, verbose=1,\n",
    "            tensorboard_log=\"log/ppo_reward_empty_random_no_step_cap\"\n",
    "            )\n",
    "\n",
    "# Train the model\n",
    "model2.learn(total_timesteps=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"models/ppo_reward_empty_random_no_step_cap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward: 99.62877734000001 +/- 10.619204641583398\n"
     ]
    }
   ],
   "source": [
    "model2 = PPO.load(\"models/ppo_reward_empty_random_no_step_cap\",env=env_vec_ran)\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model2, env=env_vec_ran, n_eval_episodes=50)\n",
    "print(f\"Mean Reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = [100.99648]\n",
      "Episode 2: Total Reward = [101.27539]\n",
      "Episode 3: Total Reward = [100.99648]\n",
      "Episode 4: Total Reward = [101.28242]\n",
      "Episode 5: Total Reward = [100.99648]\n",
      "Episode 6: Total Reward = [101.27803]\n",
      "Episode 7: Total Reward = [100.992966]\n",
      "Episode 8: Total Reward = [100.99209]\n",
      "Episode 9: Total Reward = [101.084175]\n",
      "Episode 10: Total Reward = [101.279785]\n",
      "Episode 11: Total Reward = [101.07715]\n",
      "Episode 12: Total Reward = [101.26749]\n",
      "Episode 13: Total Reward = [101.180664]\n",
      "Episode 14: Total Reward = [101.28155]\n",
      "Episode 15: Total Reward = [101.561325]\n",
      "Episode 16: Total Reward = [101.08594]\n",
      "Episode 17: Total Reward = [101.18242]\n",
      "Episode 18: Total Reward = [101.08154]\n",
      "Episode 19: Total Reward = [101.27276]\n",
      "Episode 20: Total Reward = [101.089455]\n",
      "Episode 21: Total Reward = [100.99121]\n",
      "Episode 22: Total Reward = [101.08242]\n",
      "Episode 23: Total Reward = [101.17715]\n",
      "Episode 24: Total Reward = [100.99033]\n",
      "Episode 25: Total Reward = [110.774414]\n",
      "Episode 26: Total Reward = [101.18417]\n",
      "Episode 27: Total Reward = [101.09121]\n",
      "Episode 28: Total Reward = [100.99912]\n",
      "Episode 29: Total Reward = [100.992966]\n",
      "Episode 30: Total Reward = [101.171875]\n",
      "Episode 31: Total Reward = [101.0833]\n",
      "Episode 32: Total Reward = [100.99473]\n",
      "Episode 33: Total Reward = [101.27803]\n",
      "Episode 34: Total Reward = [101.180664]\n",
      "Episode 35: Total Reward = [101.27891]\n",
      "Episode 36: Total Reward = [101.17627]\n",
      "Episode 37: Total Reward = [101.080666]\n",
      "Episode 38: Total Reward = [101.08858]\n",
      "Episode 39: Total Reward = [100.989456]\n",
      "Episode 40: Total Reward = [100.995605]\n",
      "Episode 41: Total Reward = [100.]\n",
      "Episode 42: Total Reward = [106.4205]\n",
      "Episode 43: Total Reward = [100.99209]\n",
      "Episode 44: Total Reward = [101.17451]\n",
      "Episode 45: Total Reward = [101.09209]\n",
      "Episode 46: Total Reward = [100.98769]\n",
      "Episode 47: Total Reward = [101.273636]\n",
      "Episode 48: Total Reward = [101.08242]\n",
      "Episode 49: Total Reward = [101.180664]\n",
      "Episode 50: Total Reward = [101.276276]\n",
      "Average Reward over 50 episodes: [101.40671]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "total_rewards = []  # List to store total rewards for each episode\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs = env_vec_ran.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model2.predict(obs)\n",
    "        obs, reward, done, info = env_vec_ran.step(action)\n",
    "        #print(done)\n",
    "        total_reward += reward\n",
    "        env_vec_ran.render('human')  # Render the environment at each step\n",
    "        #time.sleep(0.05)  # Adjust this to control the speed of the rendering\n",
    "    total_rewards.append(total_reward)  # Store the total reward for this episode\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "# Calculate the average reward across all episodes\n",
    "average_reward = sum(total_rewards) / num_episodes\n",
    "print(f\"Average Reward over {num_episodes} episodes: {average_reward}\")\n",
    "\n",
    "env_vec_ran.close()  # Close the environment when done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Four rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id3 = \"MiniGrid-FourRooms-v0\"\n",
    "def create_env():\n",
    "    env = gym.make(env_id3, render_mode=\"rgb_array\")\n",
    "    env = ActionWrapper(env)\n",
    "    env = RewardShapingWrapper3(env)\n",
    "    env = FlatObsWrapper(env)  \n",
    "    return env\n",
    "\n",
    "env_vec_four = make_vec_env(create_env, n_envs=1)\n",
    "env_vec_four2 = make_vec_env(create_env, n_envs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to log/ppo_reward_four_no_step_cap/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 81.4     |\n",
      "|    ep_rew_mean     | -1.98    |\n",
      "| time/              |          |\n",
      "|    fps             | 3207     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 81.9        |\n",
      "|    ep_rew_mean          | -0.541      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2005        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010081182 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.357      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.252       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    value_loss           | 0.307       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 81.5        |\n",
      "|    ep_rew_mean          | -1.72       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1765        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011258326 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.00444    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.268       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    value_loss           | 2.29        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 82.7         |\n",
      "|    ep_rew_mean          | -1.21        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1693         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137529485 |\n",
      "|    clip_fraction        | 0.199        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -0.0676      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00191      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    value_loss           | 0.196        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 80.5       |\n",
      "|    ep_rew_mean          | -0.971     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1661       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 24         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01584828 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.968     |\n",
      "|    explained_variance   | -0.00769   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0366    |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    value_loss           | 0.531      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.2        |\n",
      "|    ep_rew_mean          | -0.794      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1628        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014900908 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | -0.0268     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.628       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.284       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.9        |\n",
      "|    ep_rew_mean          | -0.247      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020287812 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.788      |\n",
      "|    explained_variance   | 0.00356     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0273      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.348       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.9        |\n",
      "|    ep_rew_mean          | -0.496      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1553        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012669371 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.714      |\n",
      "|    explained_variance   | 0.0112      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    value_loss           | 0.611       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.2        |\n",
      "|    ep_rew_mean          | 0.816       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1546        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014584778 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.592      |\n",
      "|    explained_variance   | 0.0489      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0324     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.8        |\n",
      "|    ep_rew_mean          | 0.473       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1530        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014882103 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.00157     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0874      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    value_loss           | 1.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.6        |\n",
      "|    ep_rew_mean          | 1.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1524        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004988928 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.406      |\n",
      "|    explained_variance   | 0.00603     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0328      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 0.525       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.4        |\n",
      "|    ep_rew_mean          | 0.547       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1518        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013651224 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | -0.00271    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    value_loss           | 1.89        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.2         |\n",
      "|    ep_rew_mean          | 1.31         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1514         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058568344 |\n",
      "|    clip_fraction        | 0.0464       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.251       |\n",
      "|    explained_variance   | -0.0069      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.568        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    value_loss           | 0.487        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.9        |\n",
      "|    ep_rew_mean          | 0.614       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1515        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009347533 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.203      |\n",
      "|    explained_variance   | -0.00765    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0188      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    value_loss           | 1.46        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 78.1         |\n",
      "|    ep_rew_mean          | 2.66         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1513         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081527885 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.157       |\n",
      "|    explained_variance   | -0.00433     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.32         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    value_loss           | 0.474        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.5        |\n",
      "|    ep_rew_mean          | 0.632       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1510        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008181725 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.136      |\n",
      "|    explained_variance   | -0.000939   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.343       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 75.7         |\n",
      "|    ep_rew_mean          | 1.59         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1511         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076264837 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.107       |\n",
      "|    explained_variance   | -0.0104      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0571       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    value_loss           | 0.75         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.9        |\n",
      "|    ep_rew_mean          | 1.77        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1506        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005943903 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0796     |\n",
      "|    explained_variance   | -0.00224    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 1.58        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 75.5         |\n",
      "|    ep_rew_mean          | 0.243        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1504         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040996657 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0605      |\n",
      "|    explained_variance   | -0.000217    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.504        |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    value_loss           | 1.78         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.8        |\n",
      "|    ep_rew_mean          | 0.0322      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1504        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030941678 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.116      |\n",
      "|    explained_variance   | -0.0767     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.047      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.0972      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.2         |\n",
      "|    ep_rew_mean          | 1.43         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1505         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132597415 |\n",
      "|    clip_fraction        | 0.07         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.156       |\n",
      "|    explained_variance   | -0.0163      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000842     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 0.218        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 73.4         |\n",
      "|    ep_rew_mean          | 0.626        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1506         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113199605 |\n",
      "|    clip_fraction        | 0.0652       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.144       |\n",
      "|    explained_variance   | -0.00222     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.754        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    value_loss           | 1.88         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.3        |\n",
      "|    ep_rew_mean          | 0.622       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1502        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010166228 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.151      |\n",
      "|    explained_variance   | -0.0336     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.283       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    value_loss           | 0.479       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.2        |\n",
      "|    ep_rew_mean          | 0.615       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1501        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009881355 |\n",
      "|    clip_fraction        | 0.0406      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0925     |\n",
      "|    explained_variance   | 0.00627     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0451      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    value_loss           | 0.456       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.7        |\n",
      "|    ep_rew_mean          | 0.492       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1501        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012421595 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0653     |\n",
      "|    explained_variance   | -0.00616    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.665       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    value_loss           | 0.616       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.1        |\n",
      "|    ep_rew_mean          | 0.537       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1503        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011834513 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0555     |\n",
      "|    explained_variance   | -0.0358     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0135      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 0.277       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70          |\n",
      "|    ep_rew_mean          | 2.62        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1503        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011923762 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0815     |\n",
      "|    explained_variance   | -0.00302    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.206       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    value_loss           | 0.472       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.4        |\n",
      "|    ep_rew_mean          | 1.64        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1504        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028141003 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.104      |\n",
      "|    explained_variance   | 0.000164    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.41        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.8        |\n",
      "|    ep_rew_mean          | 0.188       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1505        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037152115 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.118      |\n",
      "|    explained_variance   | -0.00484    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    value_loss           | 1.93        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.3        |\n",
      "|    ep_rew_mean          | 1.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1505        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013219055 |\n",
      "|    clip_fraction        | 0.0612      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.119      |\n",
      "|    explained_variance   | -0.0612     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.5        |\n",
      "|    ep_rew_mean          | 1.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1503        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007941936 |\n",
      "|    clip_fraction        | 0.0471      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.104      |\n",
      "|    explained_variance   | -0.000339   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.315       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    value_loss           | 1.84        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 70.5         |\n",
      "|    ep_rew_mean          | 1.06         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047885147 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0896      |\n",
      "|    explained_variance   | -0.00469     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0561       |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000712    |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 74.8         |\n",
      "|    ep_rew_mean          | 0.443        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1494         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060491133 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0863      |\n",
      "|    explained_variance   | -0.00316     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0805       |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    value_loss           | 0.973        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.7        |\n",
      "|    ep_rew_mean          | 0.249       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008189777 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0724     |\n",
      "|    explained_variance   | -0.0178     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 67.9       |\n",
      "|    ep_rew_mean          | 0.0442     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1491       |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 286720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03267861 |\n",
      "|    clip_fraction        | 0.0574     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | -0.0261    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.507      |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.00503   |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.5        |\n",
      "|    ep_rew_mean          | 0.184       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009513887 |\n",
      "|    clip_fraction        | 0.0684      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.148      |\n",
      "|    explained_variance   | -0.0143     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00332     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.2        |\n",
      "|    ep_rew_mean          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1484        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010159258 |\n",
      "|    clip_fraction        | 0.0423      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0995     |\n",
      "|    explained_variance   | -0.0394     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00272     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    value_loss           | 0.0702      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 72.1       |\n",
      "|    ep_rew_mean          | 0.553      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1479       |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 210        |\n",
      "|    total_timesteps      | 311296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01273481 |\n",
      "|    clip_fraction        | 0.0682     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | -0.00257   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0772     |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.00391   |\n",
      "|    value_loss           | 0.542      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.1        |\n",
      "|    ep_rew_mean          | 0.389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1477        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013610866 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.113      |\n",
      "|    explained_variance   | -0.0137     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0267      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    value_loss           | 0.575       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.7        |\n",
      "|    ep_rew_mean          | 1.66        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1477        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015234818 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0794     |\n",
      "|    explained_variance   | -0.00338    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0012      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    value_loss           | 0.246       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.2        |\n",
      "|    ep_rew_mean          | 0.314       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1476        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007046005 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0756     |\n",
      "|    explained_variance   | -0.00165    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0917      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 1.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.2        |\n",
      "|    ep_rew_mean          | 0.236       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1477        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014577829 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0776     |\n",
      "|    explained_variance   | -0.0192     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00893     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.5        |\n",
      "|    ep_rew_mean          | 1.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1477        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011038527 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0914     |\n",
      "|    explained_variance   | -0.003      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0961      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 74.8         |\n",
      "|    ep_rew_mean          | 0.806        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1478         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 243          |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057984916 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0759      |\n",
      "|    explained_variance   | -0.000625    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.487        |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.5        |\n",
      "|    ep_rew_mean          | 0.507       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1477        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016715085 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0762     |\n",
      "|    explained_variance   | -0.00704    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.363       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    value_loss           | 0.683       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.7         |\n",
      "|    ep_rew_mean          | 0.597        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1476         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 255          |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102866925 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0765      |\n",
      "|    explained_variance   | -0.00355     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.125        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 73.8         |\n",
      "|    ep_rew_mean          | 0.34         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1476         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 260          |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110381385 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0792      |\n",
      "|    explained_variance   | -0.0034      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00503      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 0.405        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73          |\n",
      "|    ep_rew_mean          | 0.219       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1476        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019558249 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.102      |\n",
      "|    explained_variance   | -0.0121     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.201       |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    value_loss           | 0.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.2        |\n",
      "|    ep_rew_mean          | 1.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1476        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016409516 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.142      |\n",
      "|    explained_variance   | -0.0077     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0307      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 70.8         |\n",
      "|    ep_rew_mean          | 1.77         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1476         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 277          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073760673 |\n",
      "|    clip_fraction        | 0.0464       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.106       |\n",
      "|    explained_variance   | 0.00024      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    value_loss           | 0.924        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.9        |\n",
      "|    ep_rew_mean          | 0.796       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1477        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010213526 |\n",
      "|    clip_fraction        | 0.0306      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0739     |\n",
      "|    explained_variance   | -0.000111   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0398      |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    value_loss           | 1.77        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.8         |\n",
      "|    ep_rew_mean          | 3.37         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1476         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 288          |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069841216 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0592      |\n",
      "|    explained_variance   | -0.00395     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.876        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    value_loss           | 0.946        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.8        |\n",
      "|    ep_rew_mean          | 0.394       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1475        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007474191 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0431     |\n",
      "|    explained_variance   | -0.00322    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.583       |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 4           |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71           |\n",
      "|    ep_rew_mean          | 0.144        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1473         |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 300          |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069224574 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0582      |\n",
      "|    explained_variance   | -0.0162      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.272        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    value_loss           | 0.212        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 71.9       |\n",
      "|    ep_rew_mean          | 1.58       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1472       |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 305        |\n",
      "|    total_timesteps      | 450560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01017666 |\n",
      "|    clip_fraction        | 0.0487     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.092     |\n",
      "|    explained_variance   | -0.0137    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00325   |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.00503   |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71           |\n",
      "|    ep_rew_mean          | 0.596        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1471         |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 311          |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055412063 |\n",
      "|    clip_fraction        | 0.0358       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0788      |\n",
      "|    explained_variance   | -0.00051     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.361        |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 1.71         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.4        |\n",
      "|    ep_rew_mean          | 0.584       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1471        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012750883 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0664     |\n",
      "|    explained_variance   | -0.00802    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0402      |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    value_loss           | 0.433       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 68.8       |\n",
      "|    ep_rew_mean          | 2.78       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1470       |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 323        |\n",
      "|    total_timesteps      | 475136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01210447 |\n",
      "|    clip_fraction        | 0.0277     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0671    |\n",
      "|    explained_variance   | -0.0066    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.175      |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.00263   |\n",
      "|    value_loss           | 0.441      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.5        |\n",
      "|    ep_rew_mean          | 0.642       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1469        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006632007 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0597     |\n",
      "|    explained_variance   | -0.00164    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0297      |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    value_loss           | 2.98        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.5        |\n",
      "|    ep_rew_mean          | 1.87        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1468        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008740578 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0582     |\n",
      "|    explained_variance   | -0.0173     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    value_loss           | 0.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.7        |\n",
      "|    ep_rew_mean          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1467        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005812026 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0533     |\n",
      "|    explained_variance   | -0.00323    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00134    |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 65.9       |\n",
      "|    ep_rew_mean          | 1.64       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1466       |\n",
      "|    iterations           | 62         |\n",
      "|    time_elapsed         | 346        |\n",
      "|    total_timesteps      | 507904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00731313 |\n",
      "|    clip_fraction        | 0.0355     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0698    |\n",
      "|    explained_variance   | -0.00689   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.282      |\n",
      "|    n_updates            | 610        |\n",
      "|    policy_gradient_loss | -0.00277   |\n",
      "|    value_loss           | 1.23       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.7        |\n",
      "|    ep_rew_mean          | 1.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005427976 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0686     |\n",
      "|    explained_variance   | -0.00284    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00554    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    value_loss           | 1.83        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.3        |\n",
      "|    ep_rew_mean          | 0.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008268075 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.102      |\n",
      "|    explained_variance   | -0.00307    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.245       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 1.52        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.4        |\n",
      "|    ep_rew_mean          | 0.595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008579935 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.108      |\n",
      "|    explained_variance   | -0.0069     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    value_loss           | 0.523       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.7        |\n",
      "|    ep_rew_mean          | 0.268       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009839687 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.118      |\n",
      "|    explained_variance   | -0.00914    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.654       |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    value_loss           | 0.523       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.3        |\n",
      "|    ep_rew_mean          | 1.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011635128 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.144      |\n",
      "|    explained_variance   | -0.0197     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.247       |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    value_loss           | 0.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.1        |\n",
      "|    ep_rew_mean          | 0.795       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1465        |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 380         |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006695671 |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.14       |\n",
      "|    explained_variance   | -0.00288    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.282       |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    value_loss           | 0.997       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.9        |\n",
      "|    ep_rew_mean          | 0.464       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1464        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011127032 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.134      |\n",
      "|    explained_variance   | -0.0123     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 0.763       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.2        |\n",
      "|    ep_rew_mean          | 1.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1463        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026094947 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0881     |\n",
      "|    explained_variance   | -0.038      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00268     |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    value_loss           | 0.238       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 73           |\n",
      "|    ep_rew_mean          | 2.38         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1462         |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 397          |\n",
      "|    total_timesteps      | 581632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069309575 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0681      |\n",
      "|    explained_variance   | -0.00166     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.173        |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    value_loss           | 2.93         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73          |\n",
      "|    ep_rew_mean          | 0.401       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1461        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010189777 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0546     |\n",
      "|    explained_variance   | -0.00304    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.527       |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.3        |\n",
      "|    ep_rew_mean          | 0.345       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1460        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011101395 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0768     |\n",
      "|    explained_variance   | -0.00113    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.183       |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.1        |\n",
      "|    ep_rew_mean          | 0.89        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1459        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014400858 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0895     |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00646    |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    value_loss           | 0.302       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.1         |\n",
      "|    ep_rew_mean          | 0.521        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1458         |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 421          |\n",
      "|    total_timesteps      | 614400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058662854 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0887      |\n",
      "|    explained_variance   | 3.7e-06      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.477        |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    value_loss           | 1.06         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71.1         |\n",
      "|    ep_rew_mean          | 0.49         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1458         |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 426          |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055910577 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0963      |\n",
      "|    explained_variance   | -0.0135      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.136        |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    value_loss           | 0.543        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.2         |\n",
      "|    ep_rew_mean          | 2.45         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1458         |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 432          |\n",
      "|    total_timesteps      | 630784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073955595 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0846      |\n",
      "|    explained_variance   | -0.00694     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.39         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    value_loss           | 0.587        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 70           |\n",
      "|    ep_rew_mean          | 0.707        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1458         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 438          |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052513634 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0676      |\n",
      "|    explained_variance   | -0.000381    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0122       |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    value_loss           | 3.16         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69.7         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1459         |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 443          |\n",
      "|    total_timesteps      | 647168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048898677 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0596      |\n",
      "|    explained_variance   | -0.00423     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.423        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    value_loss           | 1.66         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.8        |\n",
      "|    ep_rew_mean          | 0.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1459        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 449         |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006214129 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0579     |\n",
      "|    explained_variance   | -0.00946    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00248    |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    value_loss           | 0.723       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.4         |\n",
      "|    ep_rew_mean          | 1.37         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1460         |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 454          |\n",
      "|    total_timesteps      | 663552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044512246 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.055       |\n",
      "|    explained_variance   | -0.0068      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.197        |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.2        |\n",
      "|    ep_rew_mean          | 0.346       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1460        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008266182 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0778     |\n",
      "|    explained_variance   | -0.00449    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.149       |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.1        |\n",
      "|    ep_rew_mean          | 2.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1461        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 465         |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015910638 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.12       |\n",
      "|    explained_variance   | -0.0183     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0228      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.8        |\n",
      "|    ep_rew_mean          | 0.71        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1462        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010307831 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.113      |\n",
      "|    explained_variance   | 0.000802    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.095       |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69.5         |\n",
      "|    ep_rew_mean          | 1.21         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1463         |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 475          |\n",
      "|    total_timesteps      | 696320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074425233 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0984      |\n",
      "|    explained_variance   | -0.00539     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    value_loss           | 0.646        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 69.6      |\n",
      "|    ep_rew_mean          | 1.15      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1463      |\n",
      "|    iterations           | 86        |\n",
      "|    time_elapsed         | 481       |\n",
      "|    total_timesteps      | 704512    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0210961 |\n",
      "|    clip_fraction        | 0.0956    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.142    |\n",
      "|    explained_variance   | -0.00738  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00927  |\n",
      "|    n_updates            | 850       |\n",
      "|    policy_gradient_loss | -0.0101   |\n",
      "|    value_loss           | 1.33      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 72.8       |\n",
      "|    ep_rew_mean          | 2.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1464       |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 486        |\n",
      "|    total_timesteps      | 712704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01106566 |\n",
      "|    clip_fraction        | 0.0668     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.178     |\n",
      "|    explained_variance   | 0.000892   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.291      |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.00184   |\n",
      "|    value_loss           | 1.65       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 71.7       |\n",
      "|    ep_rew_mean          | -0.0125    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1465       |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 491        |\n",
      "|    total_timesteps      | 720896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01456205 |\n",
      "|    clip_fraction        | 0.0909     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.208     |\n",
      "|    explained_variance   | -0.00822   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.00459   |\n",
      "|    value_loss           | 2.38       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73          |\n",
      "|    ep_rew_mean          | 0.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1465        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 497         |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016057342 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.231      |\n",
      "|    explained_variance   | -0.00995    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.8        |\n",
      "|    ep_rew_mean          | 0.531       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1465        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013080186 |\n",
      "|    clip_fraction        | 0.0769      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.205      |\n",
      "|    explained_variance   | -0.00139    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.237       |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    value_loss           | 0.613       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71          |\n",
      "|    ep_rew_mean          | 0.929       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1464        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014970816 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.166      |\n",
      "|    explained_variance   | -0.00511    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.016       |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    value_loss           | 0.578       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70          |\n",
      "|    ep_rew_mean          | 0.717       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1464        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 514         |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014358081 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.137      |\n",
      "|    explained_variance   | -0.00804    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0622      |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 0.755       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72          |\n",
      "|    ep_rew_mean          | 1.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1465        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 519         |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008616731 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.121      |\n",
      "|    explained_variance   | -0.0118     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    value_loss           | 0.593       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 70.2       |\n",
      "|    ep_rew_mean          | 0.264      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1465       |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 525        |\n",
      "|    total_timesteps      | 770048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00771543 |\n",
      "|    clip_fraction        | 0.049      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.122     |\n",
      "|    explained_variance   | -0.0037    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.419      |\n",
      "|    n_updates            | 930        |\n",
      "|    policy_gradient_loss | -0.0021    |\n",
      "|    value_loss           | 1.94       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.2        |\n",
      "|    ep_rew_mean          | 0.271       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 530         |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012154326 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.13       |\n",
      "|    explained_variance   | -0.0455     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00704    |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.9        |\n",
      "|    ep_rew_mean          | 1.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 536         |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011634989 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.157      |\n",
      "|    explained_variance   | -0.00902    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0038     |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    value_loss           | 0.263       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.6        |\n",
      "|    ep_rew_mean          | 0.511       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 541         |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014726257 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.15       |\n",
      "|    explained_variance   | -0.00178    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.3        |\n",
      "|    ep_rew_mean          | 1.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 547         |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007259112 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.156      |\n",
      "|    explained_variance   | -0.00868    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    value_loss           | 0.579       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.5        |\n",
      "|    ep_rew_mean          | 0.552       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010499555 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.14       |\n",
      "|    explained_variance   | -0.00234    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.7        |\n",
      "|    ep_rew_mean          | 1.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1465        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006368251 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.131      |\n",
      "|    explained_variance   | 0.00291     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0526      |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 0.525       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68          |\n",
      "|    ep_rew_mean          | 0.441       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1465        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 564         |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010089658 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.118      |\n",
      "|    explained_variance   | -0.00266    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    value_loss           | 1.71        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.6        |\n",
      "|    ep_rew_mean          | 0.653       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 569         |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012445826 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.133      |\n",
      "|    explained_variance   | -0.00992    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.272       |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 0.286       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.6        |\n",
      "|    ep_rew_mean          | 1.49        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1465        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 575         |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012307033 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.175      |\n",
      "|    explained_variance   | -0.0171     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.042       |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    value_loss           | 0.456       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.7        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1464        |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 581         |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014439432 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.187      |\n",
      "|    explained_variance   | -0.00081    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    value_loss           | 2.9         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.9        |\n",
      "|    ep_rew_mean          | 0.363       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1465        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021316525 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.195      |\n",
      "|    explained_variance   | -0.0134     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0125      |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.1        |\n",
      "|    ep_rew_mean          | 1.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1465        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012670755 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.178      |\n",
      "|    explained_variance   | -0.00455    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0914      |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 0.306       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.9        |\n",
      "|    ep_rew_mean          | 1.58        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1465        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020324241 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.15       |\n",
      "|    explained_variance   | -0.0024     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0442      |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    value_loss           | 2.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.7        |\n",
      "|    ep_rew_mean          | 3.58        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013170863 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.127      |\n",
      "|    explained_variance   | -0.00263    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    value_loss           | 1.68        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.1        |\n",
      "|    ep_rew_mean          | 0.472       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 608         |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009241602 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.113      |\n",
      "|    explained_variance   | 1.42e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    value_loss           | 3.97        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 72.8       |\n",
      "|    ep_rew_mean          | 1.42       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1466       |\n",
      "|    iterations           | 110        |\n",
      "|    time_elapsed         | 614        |\n",
      "|    total_timesteps      | 901120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00837886 |\n",
      "|    clip_fraction        | 0.0533     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.111     |\n",
      "|    explained_variance   | -0.00148   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.243      |\n",
      "|    n_updates            | 1090       |\n",
      "|    policy_gradient_loss | -0.00304   |\n",
      "|    value_loss           | 0.557      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66          |\n",
      "|    ep_rew_mean          | 0.295       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013993623 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.125      |\n",
      "|    explained_variance   | -0.00334    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    value_loss           | 1.68        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.2        |\n",
      "|    ep_rew_mean          | 0.235       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 625         |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018974269 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.161      |\n",
      "|    explained_variance   | -0.0112     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.278       |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    value_loss           | 0.326       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69          |\n",
      "|    ep_rew_mean          | 1.66        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 631         |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021674061 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.127      |\n",
      "|    explained_variance   | 0.000934    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.217       |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    value_loss           | 0.322       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.8        |\n",
      "|    ep_rew_mean          | 0.599       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 636         |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010113228 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.114      |\n",
      "|    explained_variance   | -0.00233    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0119      |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    value_loss           | 1.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.7        |\n",
      "|    ep_rew_mean          | 2.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 642         |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012340845 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.136      |\n",
      "|    explained_variance   | -0.00675    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.778       |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    value_loss           | 0.522       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 73           |\n",
      "|    ep_rew_mean          | 0.578        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1466         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 648          |\n",
      "|    total_timesteps      | 950272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111587215 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.115       |\n",
      "|    explained_variance   | -0.00212     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.543        |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 2.67         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.7        |\n",
      "|    ep_rew_mean          | 0.285       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017019559 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.13       |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00179     |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    value_loss           | 0.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71          |\n",
      "|    ep_rew_mean          | 0.281       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 659         |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019578993 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.163      |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    value_loss           | 0.425       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.2        |\n",
      "|    ep_rew_mean          | 0.367       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 664         |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009849299 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.145      |\n",
      "|    explained_variance   | -0.00129    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00384    |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    value_loss           | 1.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.3        |\n",
      "|    ep_rew_mean          | 0.203       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 670         |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019109864 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.141      |\n",
      "|    explained_variance   | -0.00863    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0036     |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.6        |\n",
      "|    ep_rew_mean          | 0.446       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 675         |\n",
      "|    total_timesteps      | 991232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014006876 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.163      |\n",
      "|    explained_variance   | -0.0114     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.548       |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    value_loss           | 0.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 64.1        |\n",
      "|    ep_rew_mean          | 1.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 681         |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008329426 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.15       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.369       |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    value_loss           | 0.322       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.1        |\n",
      "|    ep_rew_mean          | 0.869       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 687         |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010441758 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.134      |\n",
      "|    explained_variance   | -0.00131    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.39        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    value_loss           | 1.44        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x34f66ee90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the PPO model\n",
    "model3 = PPO(\"MlpPolicy\", env_vec_four2, verbose=1,\n",
    "            tensorboard_log=\"log/ppo_reward_four_no_step_cap\"\n",
    "            )\n",
    "\n",
    "# Train the model\n",
    "model3.learn(total_timesteps=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save(\"models/ppo_reward_four_no_step_cap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward: 1.3715903600000001 +/- 3.7553126334404747\n"
     ]
    }
   ],
   "source": [
    "model3 = PPO.load(\"models/ppo_reward_four_no_step_cap\",env=env_vec_four)\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model3, env=env_vec_four, n_eval_episodes=50)\n",
    "print(f\"Mean Reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = [0.23766619]\n",
      "Episode 2: Total Reward = [-0.1304092]\n",
      "Episode 3: Total Reward = [-0.03447063]\n",
      "Episode 4: Total Reward = [0.76020575]\n",
      "Episode 5: Total Reward = [0.08032629]\n",
      "Episode 6: Total Reward = [-0.3582736]\n",
      "Episode 7: Total Reward = [-0.08206747]\n",
      "Episode 8: Total Reward = [0.11576329]\n",
      "Episode 9: Total Reward = [-0.2556608]\n",
      "Episode 10: Total Reward = [-0.05138635]\n",
      "Episode 11: Total Reward = [-0.57655513]\n",
      "Episode 12: Total Reward = [-0.15714954]\n",
      "Episode 13: Total Reward = [-0.10914353]\n",
      "Episode 14: Total Reward = [0.23213537]\n",
      "Episode 15: Total Reward = [0.86677706]\n",
      "Episode 16: Total Reward = [0.07554837]\n",
      "Episode 17: Total Reward = [-0.43270564]\n",
      "Episode 18: Total Reward = [0.31736016]\n",
      "Episode 19: Total Reward = [-0.03136783]\n",
      "Episode 20: Total Reward = [-0.2865913]\n",
      "Episode 21: Total Reward = [19.891245]\n",
      "Episode 22: Total Reward = [-0.16959403]\n",
      "Episode 23: Total Reward = [0.02665466]\n",
      "Episode 24: Total Reward = [-0.48664954]\n",
      "Episode 25: Total Reward = [-0.4785459]\n",
      "Episode 26: Total Reward = [0.8403881]\n",
      "Episode 27: Total Reward = [-0.3005026]\n",
      "Episode 28: Total Reward = [0.14278987]\n",
      "Episode 29: Total Reward = [0.88215166]\n",
      "Episode 30: Total Reward = [-0.13387004]\n",
      "Episode 31: Total Reward = [0.6923978]\n",
      "Episode 32: Total Reward = [-0.327393]\n",
      "Episode 33: Total Reward = [-0.43074027]\n",
      "Episode 34: Total Reward = [-0.19973396]\n",
      "Episode 35: Total Reward = [0.8713378]\n",
      "Episode 36: Total Reward = [4.6712823]\n",
      "Episode 37: Total Reward = [0.03914072]\n",
      "Episode 38: Total Reward = [-0.24790344]\n",
      "Episode 39: Total Reward = [0.8629688]\n",
      "Episode 40: Total Reward = [-0.0585374]\n",
      "Episode 41: Total Reward = [-0.23068336]\n",
      "Episode 42: Total Reward = [4.5996494]\n",
      "Episode 43: Total Reward = [-0.42459673]\n",
      "Episode 44: Total Reward = [-0.17690511]\n",
      "Episode 45: Total Reward = [0.41260764]\n",
      "Episode 46: Total Reward = [0.923]\n",
      "Episode 47: Total Reward = [0.814]\n",
      "Episode 48: Total Reward = [0.71672094]\n",
      "Episode 49: Total Reward = [-0.5545262]\n",
      "Episode 50: Total Reward = [4.816028]\n",
      "Average Reward over 50 episodes: [0.74324363]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "total_rewards = []  # List to store total rewards for each episode\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs = env_vec_four.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model3.predict(obs)\n",
    "        obs, reward, done, info = env_vec_four.step(action)\n",
    "        #print(done)\n",
    "        total_reward += reward\n",
    "        env_vec_four.render('human')  # Render the environment at each step\n",
    "        #time.sleep(0.05)  # Adjust this to control the speed of the rendering\n",
    "    total_rewards.append(total_reward)  # Store the total reward for this episode\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "# Calculate the average reward across all episodes\n",
    "average_reward = sum(total_rewards) / num_episodes\n",
    "print(f\"Average Reward over {num_episodes} episodes: {average_reward}\")\n",
    "\n",
    "env_vec_four.close()  # Close the environment when done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
