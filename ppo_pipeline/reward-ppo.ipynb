{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla PPO + action wrapper + reward shaping\n",
    "\n",
    "Run on 3 environments\n",
    "\n",
    "Empty Room\n",
    "\n",
    "Empty Room Random\n",
    "\n",
    "Four Rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import minigrid\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from minigrid.wrappers import FlatObsWrapper\n",
    "import time\n",
    "import numpy as np\n",
    "from minigrid.core.world_object import Goal\n",
    "import random\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from gymnasium.envs.registration import register\n",
    "from minigrid.core.constants import OBJECT_TO_IDX, IDX_TO_OBJECT, COLOR_TO_IDX, IDX_TO_COLOR, DIR_TO_VEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and wrap the environment\n",
    "env_id = \"MiniGrid-Empty-16x16-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ActionWrapper, self).__init__(env)\n",
    "        # Define a new action space with only the relevant actions\n",
    "        self.action_space = gym.spaces.Discrete(3)  # Only three actions: left, right, forward\n",
    "\n",
    "    def action(self, action):\n",
    "        # Map the new actions to the original actions\n",
    "        action_mapping = {\n",
    "            0: 0,  # left\n",
    "            1: 1,  # right\n",
    "            2: 2   # forward\n",
    "        }\n",
    "        return action_mapping[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardShapingWrapper1(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(RewardShapingWrapper1, self).__init__(env)\n",
    "        self.last_action = None\n",
    "        self.spin_counter = 0  # Tracks consecutive left-right turns\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info, extra = self.env.step(action)\n",
    "        current_pos = self.env.agent_pos\n",
    "\n",
    "        # Check for spinning behavior\n",
    "        if self.last_action in [0, 1] and action in [0, 1] and action != self.last_action:\n",
    "            self.spin_counter += 1\n",
    "        else:\n",
    "            self.spin_counter = 0\n",
    "\n",
    "        if self.spin_counter > 2:  # Threshold for considering it spinning\n",
    "            reward -= 10\n",
    "            self.spin_counter = 0  # Reset counter after penalty\n",
    "\n",
    "        if self.last_action == 0 and action == 1 or self.last_action == 1 and action == 0:\n",
    "            reward -= 10  # Increase penalty for oscillating between left and right\n",
    "\n",
    "        self.last_action = action\n",
    "        return obs, reward, done, info, extra\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        self.last_action = None\n",
    "        self.spin_counter = 0\n",
    "        return obs\n",
    "\n",
    "    def is_facing_wall(self):\n",
    "        x, y = self.env.agent_pos\n",
    "        direction_idx = self.env.agent_dir\n",
    "        delta = self.env.DIR_TO_VEC[direction_idx]\n",
    "        next_x, next_y = x + delta[0], y + delta[1]\n",
    "        if 0 <= next_x < self.env.width and 0 <= next_y < self.env.height:\n",
    "            next_cell = self.env.grid.get(next_x, next_y)\n",
    "            return next_cell is not None and next_cell.type == 'wall'\n",
    "        return False\n",
    "    \n",
    "    def get_goal_position(self):\n",
    "        for x in range(self.env.width):\n",
    "            for y in range(self.env.height):\n",
    "                if self.env.grid.get(x, y) is not None and isinstance(self.env.grid.get(x, y), Goal):\n",
    "                    return (x, y)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardShapingWrapper2(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.last_room_id = None\n",
    "        self.goal_position = None\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        self.last_room_id = self.get_room_id(obs)\n",
    "        self.goal_position = self.find_goal_position()\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        current_room_id = self.get_room_id(obs)\n",
    "        agent_pos = self.env.agent_pos\n",
    "\n",
    "        # Check if the agent has passed through a doorway\n",
    "        if current_room_id != self.last_room_id:\n",
    "            reward += 0.1  \n",
    "            self.last_room_id = current_room_id\n",
    "\n",
    "        # Check if the goal is reached by comparing positions\n",
    "        if tuple(agent_pos) == self.goal_position:\n",
    "            reward += 100 \n",
    "            terminated = True  \n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def get_room_id(self, obs):\n",
    "        # Implement logic to determine the room ID based on the agent's position\n",
    "        agent_pos = self.env.agent_pos\n",
    "        if agent_pos[0] < self.env.width // 2:\n",
    "            if agent_pos[1] < self.env.height // 2:\n",
    "                return 0  \n",
    "            else:\n",
    "                return 2  \n",
    "        else:\n",
    "            if agent_pos[1] < self.env.height // 2:\n",
    "                return 1  \n",
    "            else:\n",
    "                return 3  \n",
    "\n",
    "    def find_goal_position(self):\n",
    "        # Scan the grid to find the goal's position\n",
    "        for x in range(self.env.width):\n",
    "            for y in range(self.env.height):\n",
    "                if isinstance(self.env.grid.get(x, y), Goal):\n",
    "                    return (x, y)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardShapingWrapper3(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(RewardShapingWrapper3, self).__init__(env)\n",
    "        self.last_pos = None\n",
    "        self.goal_pos = None\n",
    "        self.stuck_counter = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        action = self.noisy_action(action)  # Apply noise to the action for exploration\n",
    "        obs, reward, done, info, extra = self.env.step(action)\n",
    "        current_pos = self.env.agent_pos\n",
    "\n",
    "        if self.goal_pos is None:\n",
    "            self.goal_pos = self.get_goal_position()\n",
    "\n",
    "        current_room = self.get_room(current_pos)\n",
    "        last_room = self.get_room(self.last_pos) if self.last_pos else None\n",
    "\n",
    "        # Check if transitioned to a new room\n",
    "        if last_room and current_room and last_room != current_room:\n",
    "            reward += 5.0  # Reward for moving to a new room\n",
    "\n",
    "        # Additional vector to the nearest gap or doorway\n",
    "        nearest_gap_vector = self.get_vector_to_nearest_gap(current_pos)\n",
    "        obs['nearest_gap_direction'] = nearest_gap_vector  # Ensure obs is a dictionary\n",
    "\n",
    "        # Assuming obs is a dictionary that includes 'image' and possibly other keys\n",
    "        goal_direction = self.get_goal_direction(current_pos)\n",
    "        # If you intend to add goal_direction to obs, you should add it as a new key-value pair\n",
    "        obs['goal_direction'] = goal_direction  # Add it like this if obs is a dictionary\n",
    "\n",
    "        # Reward shaping calculations\n",
    "        if self.last_pos is not None and self.goal_pos is not None:\n",
    "            distance_reward = self.calculate_reward_shaping(current_pos)\n",
    "            additional_reward = self.additional_rewards(action, current_pos, self.last_pos)\n",
    "            reward += distance_reward + additional_reward\n",
    "\n",
    "        if np.array_equal(current_pos, self.goal_pos):\n",
    "            reward += 100\n",
    "            done = True\n",
    "\n",
    "        if self.last_pos == current_pos:\n",
    "            self.stuck_counter += 1\n",
    "        else:\n",
    "            self.stuck_counter = 0\n",
    "\n",
    "        if self.stuck_counter > 3:\n",
    "            obs = self.nudge_agent(current_pos) or obs\n",
    "            self.stuck_counter = 0\n",
    "\n",
    "        self.last_pos = current_pos\n",
    "        return obs, reward, done, info, extra\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        self.last_pos = self.env.agent_pos\n",
    "        self.goal_pos = self.get_goal_position()\n",
    "        self.gaps = self.find_gaps()  # Find gaps upon reset\n",
    "        return obs\n",
    "    \n",
    "    def get_vector_to_nearest_gap(self, current_pos):\n",
    "        if not self.gaps:\n",
    "            return np.zeros(2)  # Default to zero vector if no gaps identified\n",
    "\n",
    "        nearest_gap = min(self.gaps, key=lambda gap: np.linalg.norm(np.array(gap) - np.array(current_pos)))\n",
    "        direction_vector = np.array(nearest_gap) - np.array(current_pos)\n",
    "        norm = np.linalg.norm(direction_vector)\n",
    "        return direction_vector / norm if norm != 0 else direction_vector\n",
    "\n",
    "    \n",
    "    def find_gaps(self):\n",
    "        width, height = self.env.width, self.env.height\n",
    "        gaps = []\n",
    "        # Typically, gaps will be in the walls that divide the rooms\n",
    "        # We scan horizontal and vertical mid-lines for empty spaces\n",
    "        mid_vertical = width // 2\n",
    "        mid_horizontal = height // 2\n",
    "\n",
    "        # Vertical mid-line (check for empty cells)\n",
    "        for y in range(height):\n",
    "            if self.env.grid.get(mid_vertical, y) is None:\n",
    "                #print('vertical', self.env.grid.get(mid_vertical, y))\n",
    "                #print('the gap vertical mid-line is',(mid_vertical, y) )\n",
    "                gaps.append((mid_vertical, y))\n",
    "\n",
    "        # Horizontal mid-line (check for empty cells)\n",
    "        for x in range(width):\n",
    "            if self.env.grid.get(x, mid_horizontal) is None:\n",
    "                gaps.append((x, mid_horizontal))\n",
    "\n",
    "        return gaps\n",
    "\n",
    "\n",
    "    def get_goal_position(self):\n",
    "        for x in range(self.env.width):\n",
    "            for y in range(self.env.height):\n",
    "                if self.env.grid.get(x, y) is not None and isinstance(self.env.grid.get(x, y), Goal):\n",
    "                    return (x, y)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def calculate_reward_shaping(self, current_pos):\n",
    "        if not self.goal_pos:\n",
    "            return 0\n",
    "        \n",
    "        epsilon = 0.01  # Small value to avoid division by zero\n",
    "        prev_distance = np.linalg.norm(np.array(self.last_pos) - np.array(self.goal_pos))\n",
    "        current_distance = np.linalg.norm(np.array(current_pos) - np.array(self.goal_pos))\n",
    "        \n",
    "        if current_distance < prev_distance:\n",
    "            return 0.1 * (1 / (current_distance + epsilon))\n",
    "        elif current_distance > prev_distance:\n",
    "            return -0.1 * (1 / (current_distance + epsilon))\n",
    "        return 0\n",
    "\n",
    "    def additional_rewards(self, action, current_pos, prev_pos):\n",
    "        prev_distance = np.linalg.norm(np.array(prev_pos) - np.array(self.goal_pos))\n",
    "        current_distance = np.linalg.norm(np.array(current_pos) - np.array(self.goal_pos))\n",
    "        distance_change = prev_distance - current_distance\n",
    "        \n",
    "        if action in [0, 1] and distance_change <= 0:\n",
    "            return -0.05  # Unchanged, penalty for non-improvement\n",
    "        \n",
    "        reward = 0\n",
    "        if action == 2 and distance_change > 0:\n",
    "            reward = min(0.05 * distance_change, 1.0)  # Cap the reward to avoid excessively high values\n",
    "\n",
    "        return reward\n",
    "    \n",
    "\n",
    "    def get_goal_direction(self, current_pos):\n",
    "        if not self.goal_pos:\n",
    "            return np.zeros_like(current_pos)  # Return a zero vector if goal position is not set\n",
    "        # Assuming current_pos and goal_pos are numpy arrays or can be converted to them\n",
    "        direction_vector = np.array(self.goal_pos) - np.array(current_pos)\n",
    "        # Normalize the vector\n",
    "        norm = np.linalg.norm(direction_vector)\n",
    "        if norm == 0:\n",
    "            return direction_vector  # Avoid division by zero if already at the goal\n",
    "        return direction_vector / norm\n",
    "    \n",
    "    def noisy_action(self, action):\n",
    "        # Add random noise to the action occasionally\n",
    "        if random.random() < 0.1:  # With 10% probability, alter the action randomly\n",
    "            return random.choice([0, 1, 2])  # Assuming actions are 0, 1, 2\n",
    "        return action\n",
    "    \n",
    "\n",
    "    def get_possible_moves(self, current_pos):\n",
    "        moves = []\n",
    "        directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # Directions: up, down, left, right\n",
    "\n",
    "        for dx, dy in directions:\n",
    "            new_pos = (current_pos[0] + dx, current_pos[1] + dy)\n",
    "            if self.is_position_valid(new_pos):\n",
    "                moves.append(new_pos)\n",
    "        return moves\n",
    "\n",
    "    def is_position_valid(self, pos):\n",
    "        x, y = pos\n",
    "        # Check if within grid bounds\n",
    "        if 0 <= x < self.env.width and 0 <= y < self.env.height:\n",
    "            # Check if the cell is empty (None means empty in MiniGrid)\n",
    "            return self.env.grid.get(x, y) is None\n",
    "        return False\n",
    "    \n",
    "    def nudge_agent(self, current_pos):\n",
    "        possible_moves = self.get_possible_moves(current_pos)\n",
    "        if possible_moves:\n",
    "            new_pos = random.choice(possible_moves)\n",
    "            self.env.agent_pos = new_pos  # Assuming you can set the position\n",
    "            # Simulate a no-op or a neutral action to update state and get observation\n",
    "            obs, _, _, _, _ = self.env.step(0)  # Consider '0' as a no-op action, if applicable\n",
    "            return obs\n",
    "        # If no moves are possible or other issues arise, return a default observation\n",
    "        return np.zeros(self.env.observation_space.shape)  # Adjust based on the specific obs space\n",
    "    \n",
    "    def get_room(self, position):\n",
    "        x, y = position\n",
    "        if x < 10 and y < 10:\n",
    "            return 1  # Top-left room\n",
    "        elif x >= 10 and y < 10:\n",
    "            return 2  # Top-right room\n",
    "        elif x < 10 and y >= 10:\n",
    "            return 3  # Bottom-left room\n",
    "        elif x >= 10 and y >= 10:\n",
    "            return 4  # Bottom-right room\n",
    "        return 0  # Should not happen unless position is out of expected range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env():\n",
    "    env = gym.make(env_id, render_mode=\"rgb_array\")#,max_episode_steps=200)\n",
    "    env = ActionWrapper(env)\n",
    "    env = RewardShapingWrapper1(env)\n",
    "    env = FlatObsWrapper(env)  \n",
    "    return env\n",
    "\n",
    "# Use the function in make_vec_env\n",
    "env_vec = make_vec_env(create_env, n_envs=1)\n",
    "env_vec2 = make_vec_env(create_env, n_envs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to log/ppo_reward_empty_no_step_cap/PPO_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthony/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 808       |\n",
      "|    ep_rew_mean     | -1.99e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 5217      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 1         |\n",
      "|    total_timesteps | 8192      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 807         |\n",
      "|    ep_rew_mean          | -1.76e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2734        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012810546 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.000608   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 209         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 798         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 755         |\n",
      "|    ep_rew_mean          | -1.44e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2396        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016515259 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -3.81e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 402         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 682         |\n",
      "|    ep_rew_mean          | -1.13e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2254        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019161917 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.978      |\n",
      "|    explained_variance   | -1.07e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 602        |\n",
      "|    ep_rew_mean          | -891       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2176       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01972229 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.863     |\n",
      "|    explained_variance   | -2.26e-06  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 139        |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0283    |\n",
      "|    value_loss           | 163        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 519         |\n",
      "|    ep_rew_mean          | -650        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2132        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013884058 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.754      |\n",
      "|    explained_variance   | -4.77e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 96.5        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 383         |\n",
      "|    ep_rew_mean          | -246        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2100        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007586711 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.644      |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 298          |\n",
      "|    ep_rew_mean          | -79.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2076         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061263647 |\n",
      "|    clip_fraction        | 0.0802       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.1         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00951     |\n",
      "|    value_loss           | 80           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 267          |\n",
      "|    ep_rew_mean          | -37.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2058         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033904875 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.294        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    value_loss           | 56           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 219          |\n",
      "|    ep_rew_mean          | -18          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2044         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027796263 |\n",
      "|    clip_fraction        | 0.0513       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.271        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 132          |\n",
      "|    ep_rew_mean          | -4.92        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2032         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033517373 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.35        |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69.3         |\n",
      "|    ep_rew_mean          | -0.561       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2023         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023940396 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.314       |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.65         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 56.2         |\n",
      "|    ep_rew_mean          | 0.151        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2019         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020699045 |\n",
      "|    clip_fraction        | 0.0424       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.285       |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.53         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 42.9         |\n",
      "|    ep_rew_mean          | 0.262        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2013         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033162716 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.249       |\n",
      "|    explained_variance   | 0.267        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.66         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00683     |\n",
      "|    value_loss           | 12.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.4        |\n",
      "|    ep_rew_mean          | 0.359       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2005        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002994813 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.21       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.23        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    value_loss           | 4.76        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 37.1         |\n",
      "|    ep_rew_mean          | 0.167        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1998         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018901773 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.183       |\n",
      "|    explained_variance   | 0.0918       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 44.7         |\n",
      "|    ep_rew_mean          | 0.861        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1993         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018325591 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.152       |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.394        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 1.56         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.3         |\n",
      "|    ep_rew_mean          | 0.868        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1990         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026741829 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.149       |\n",
      "|    explained_variance   | 0.204        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.078        |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    value_loss           | 0.437        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.4         |\n",
      "|    ep_rew_mean          | 0.969        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1987         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010574352 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.116       |\n",
      "|    explained_variance   | -0.00191     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0275       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 0.377        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.9         |\n",
      "|    ep_rew_mean          | 0.974        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1984         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015647912 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.108       |\n",
      "|    explained_variance   | 0.0636       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00548     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 0.263        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.1        |\n",
      "|    ep_rew_mean          | 0.756       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1983        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017484419 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.104      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0146     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.0754      |\n",
      "|    value_loss           | 0.00941     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.4         |\n",
      "|    ep_rew_mean          | 0.871        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1982         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037616894 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0939      |\n",
      "|    explained_variance   | 0.0159       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.714        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    value_loss           | 0.255        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.1         |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1981         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123866685 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0648      |\n",
      "|    explained_variance   | 0.141        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00411     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    value_loss           | 0.0422       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.5        |\n",
      "|    ep_rew_mean          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1979        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001787225 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0454     |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00078     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    value_loss           | 0.00384     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.8         |\n",
      "|    ep_rew_mean          | 0.943        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1977         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040248903 |\n",
      "|    clip_fraction        | 0.0665       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0531      |\n",
      "|    explained_variance   | 0.0589       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000582    |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 0.0914       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x3181516f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env_vec2, verbose=1,\n",
    "            tensorboard_log=\"log/ppo_reward_empty_no_step_cap\"\n",
    "            )\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/ppo_reward_empty_no_step_cap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward: 0.9762699999999999 +/- 1.1102230246251565e-16\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"models/ppo_reward_empty_no_step_cap\",env=env_vec)\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env=env_vec, n_eval_episodes=50)\n",
    "print(f\"Mean Reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = [0.]\n",
      "Episode 2: Total Reward = [0.90419924]\n",
      "Episode 3: Total Reward = [0.79960936]\n",
      "Episode 4: Total Reward = [0.92880857]\n",
      "Episode 5: Total Reward = [0.97626954]\n",
      "Episode 6: Total Reward = [0.5974609]\n",
      "Episode 7: Total Reward = [0.9024414]\n",
      "Episode 8: Total Reward = [0.]\n",
      "Episode 9: Total Reward = [0.7169922]\n",
      "Episode 10: Total Reward = [0.8400391]\n",
      "Episode 11: Total Reward = [0.51835936]\n",
      "Episode 12: Total Reward = [0.5482422]\n",
      "Episode 13: Total Reward = [0.74248046]\n",
      "Episode 14: Total Reward = [0.869043]\n",
      "Episode 15: Total Reward = [0.94199216]\n",
      "Episode 16: Total Reward = [0.5552734]\n",
      "Episode 17: Total Reward = [0.8101562]\n",
      "Episode 18: Total Reward = [0.86728513]\n",
      "Episode 19: Total Reward = [0.6220703]\n",
      "Episode 20: Total Reward = [0.93671876]\n",
      "Episode 21: Total Reward = [0.81279296]\n",
      "Episode 22: Total Reward = [0.97626954]\n",
      "Episode 23: Total Reward = [0.93759763]\n",
      "Episode 24: Total Reward = [0.5913086]\n",
      "Episode 25: Total Reward = [0.859375]\n",
      "Episode 26: Total Reward = [0.97626954]\n",
      "Episode 27: Total Reward = [0.58427733]\n",
      "Episode 28: Total Reward = [0.9393555]\n",
      "Episode 29: Total Reward = [0.8417969]\n",
      "Episode 30: Total Reward = [0.85849607]\n",
      "Episode 31: Total Reward = [0.8576172]\n",
      "Episode 32: Total Reward = [0.97626954]\n",
      "Episode 33: Total Reward = [0.7328125]\n",
      "Episode 34: Total Reward = [0.59833986]\n",
      "Episode 35: Total Reward = [0.93408203]\n",
      "Episode 36: Total Reward = [0.80927736]\n",
      "Episode 37: Total Reward = [0.8954102]\n",
      "Episode 38: Total Reward = [0.9085938]\n",
      "Episode 39: Total Reward = [0.97626954]\n",
      "Episode 40: Total Reward = [0.9753906]\n",
      "Episode 41: Total Reward = [0.85234374]\n",
      "Episode 42: Total Reward = [0.89277345]\n",
      "Episode 43: Total Reward = [0.69677734]\n",
      "Episode 44: Total Reward = [0.97626954]\n",
      "Episode 45: Total Reward = [0.65898436]\n",
      "Episode 46: Total Reward = [0.6194336]\n",
      "Episode 47: Total Reward = [0.775]\n",
      "Episode 48: Total Reward = [0.6897461]\n",
      "Episode 49: Total Reward = [0.97626954]\n",
      "Episode 50: Total Reward = [0.93583983]\n",
      "Average Reward over 50 episodes: [0.78384966]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "total_rewards = []  # List to store total rewards for each episode\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs = env_vec.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env_vec.step(action)\n",
    "        #print(done)\n",
    "        total_reward += reward\n",
    "        env_vec.render('human')  # Render the environment at each step\n",
    "        #time.sleep(0.05)  # Adjust this to control the speed of the rendering\n",
    "    total_rewards.append(total_reward)  # Store the total reward for this episode\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "# Calculate the average reward across all episodes\n",
    "average_reward = sum(total_rewards) / num_episodes\n",
    "print(f\"Average Reward over {num_episodes} episodes: {average_reward}\")\n",
    "\n",
    "env_vec.close()  # Close the environment when done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empty random room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "register(\n",
    "    id='custom_empty-v0',\n",
    "    entry_point='emptyrandom:RandomGoalEmptyEnv',\n",
    "    kwargs={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 'custom_empty-v0' is registered.\n"
     ]
    }
   ],
   "source": [
    "#gym.pprint_registry()  # to see all registered environments\n",
    "\n",
    "if 'custom_empty-v0' in gym.envs.registry:\n",
    "    print(\"Environment 'custom_empty-v0' is registered.\")\n",
    "else:\n",
    "    print(\"Environment 'custom_empty-v0' is NOT registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id2 = 'custom_empty-v0'\n",
    "def create_env():\n",
    "    env = gym.make(env_id2, render_mode=\"rgb_array\",size=16)#,max_episode_steps=200)\n",
    "    env = ActionWrapper(env)\n",
    "    env = RewardShapingWrapper2(env)\n",
    "    env = FlatObsWrapper(env)  \n",
    "    return env\n",
    "\n",
    "env_vec_ran = make_vec_env(create_env, n_envs=1)\n",
    "env_vec_ran2 = make_vec_env(create_env, n_envs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthony/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_goal_position to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_goal_position` for environment variables or `env.get_wrapper_attr('get_goal_position')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomGoalEmptyEnv' object has no attribute 'get_goal_position'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m model2 \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env_vec_ran2, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      3\u001b[0m             tensorboard_log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog/ppo_reward_empty_random\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m             )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:287\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOnPolicyAlgorithm,\n\u001b[1;32m    278\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    284\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOnPolicyAlgorithm:\n\u001b[1;32m    285\u001b[0m     iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 287\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/stable_baselines3/common/base_class.py:423\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[0;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_num_timesteps \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;66;03m# Retrieve unnormalized observation for saving into the buffer\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:77\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m     76\u001b[0m     maybe_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m---> 77\u001b[0m     obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_seeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmaybe_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/gymnasium/core.py:515\u001b[0m, in \u001b[0;36mObservationWrapper.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`reset`, returning a modified observation using :meth:`self.observation`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 515\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(obs), info\n",
      "Cell \u001b[0;32mIn[7], line 63\u001b[0m, in \u001b[0;36mRewardShapingWrapper2.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# Accept any additional keyword arguments\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# Reset the underlying environment\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoal_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_goal_position\u001b[49m()  \u001b[38;5;66;03m# Retrieve the updated goal position\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/gymnasium/core.py:315\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccessing private attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is prohibited\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to get variables from other wrappers is deprecated and will be removed in v1.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get this variable you can do `env.unwrapped.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` for environment variables or `env.get_wrapper_attr(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` that will search the reminding wrappers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m )\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/gymnasium/core.py:315\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccessing private attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is prohibited\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to get variables from other wrappers is deprecated and will be removed in v1.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get this variable you can do `env.unwrapped.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` for environment variables or `env.get_wrapper_attr(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` that will search the reminding wrappers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m )\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/cs5756-project/lib/python3.10/site-packages/gymnasium/core.py:315\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccessing private attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is prohibited\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to get variables from other wrappers is deprecated and will be removed in v1.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get this variable you can do `env.unwrapped.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` for environment variables or `env.get_wrapper_attr(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` that will search the reminding wrappers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m )\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomGoalEmptyEnv' object has no attribute 'get_goal_position'"
     ]
    }
   ],
   "source": [
    "# Initialize the PPO model\n",
    "model2 = PPO(\"MlpPolicy\", env_vec_ran2, verbose=1,\n",
    "            tensorboard_log=\"log/ppo_reward_empty_random\"\n",
    "            )\n",
    "\n",
    "# Train the model\n",
    "model2.learn(total_timesteps=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/ppo_reward_empty_random_no_step_cap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "model2.save(\"models/ppo_reward_empty_random_no_step_cap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = PPO.load(\"models/ppo_reward_empty_random_no_step_cap\",env=env_vec_ran)\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model2, env=env_vec_ran, n_eval_episodes=50)\n",
    "print(f\"Mean Reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 50\n",
    "total_rewards = []  # List to store total rewards for each episode\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs = env_vec_ran.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model2.predict(obs)\n",
    "        obs, reward, done, info = env_vec_ran.step(action)\n",
    "        #print(done)\n",
    "        total_reward += reward\n",
    "        env_vec_ran.render('human')  # Render the environment at each step\n",
    "        #time.sleep(0.05)  # Adjust this to control the speed of the rendering\n",
    "    total_rewards.append(total_reward)  # Store the total reward for this episode\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "# Calculate the average reward across all episodes\n",
    "average_reward = sum(total_rewards) / num_episodes\n",
    "print(f\"Average Reward over {num_episodes} episodes: {average_reward}\")\n",
    "\n",
    "env_vec_ran.close()  # Close the environment when done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Four rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id3 = \"MiniGrid-FourRooms-v0\"\n",
    "def create_env():\n",
    "    env = gym.make(env_id3, render_mode=\"rgb_array\")\n",
    "    env = ActionWrapper(env)\n",
    "    env = RewardShapingWrapper3(env)\n",
    "    env = FlatObsWrapper(env)  \n",
    "    return env\n",
    "\n",
    "env_vec_four = make_vec_env(create_env, n_envs=1)\n",
    "env_vec_four2 = make_vec_env(create_env, n_envs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to log/ppo_reward_four/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 82.1     |\n",
      "|    ep_rew_mean     | -1.78    |\n",
      "| time/              |          |\n",
      "|    fps             | 3153     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 81.6        |\n",
      "|    ep_rew_mean          | -1.51       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2037        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019222336 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.337      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0516      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.5        |\n",
      "|    ep_rew_mean          | -1.57       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1841        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012244092 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.0161     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    value_loss           | 0.461       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | -1.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1733        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015536137 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | -0.0427     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0247      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.6        |\n",
      "|    ep_rew_mean          | -0.813      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1690        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015727988 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.923      |\n",
      "|    explained_variance   | 0.0021      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000468   |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.2        |\n",
      "|    ep_rew_mean          | -0.362      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1655        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018467706 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | -0.0032     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00563     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.304       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 74.9       |\n",
      "|    ep_rew_mean          | -0.609     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1631       |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01029501 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.717     |\n",
      "|    explained_variance   | 0.000743   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.688      |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00526   |\n",
      "|    value_loss           | 1.74       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.2        |\n",
      "|    ep_rew_mean          | -0.122      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1622        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014740532 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.641      |\n",
      "|    explained_variance   | 0.015       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000277   |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.7        |\n",
      "|    ep_rew_mean          | 1.58        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1614        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012274936 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.528      |\n",
      "|    explained_variance   | 0.0123      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    value_loss           | 0.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.6        |\n",
      "|    ep_rew_mean          | 0.525       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1607        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009136811 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.471      |\n",
      "|    explained_variance   | 0.00349     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.522       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    value_loss           | 2.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.5        |\n",
      "|    ep_rew_mean          | 0.478       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1602        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010453813 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.398      |\n",
      "|    explained_variance   | -0.00658    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.346       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    value_loss           | 0.929       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76          |\n",
      "|    ep_rew_mean          | 0.671       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1595        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012392756 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | -0.0229     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    value_loss           | 0.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.1        |\n",
      "|    ep_rew_mean          | 0.481       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1592        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007694819 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | -0.004      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    value_loss           | 0.846       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.6        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1589        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009465363 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | -0.00647    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0103     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    value_loss           | 2.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.5        |\n",
      "|    ep_rew_mean          | 2.71        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009757724 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.213      |\n",
      "|    explained_variance   | -0.0434     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0696      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.6        |\n",
      "|    ep_rew_mean          | 1.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005428194 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.169      |\n",
      "|    explained_variance   | -0.000724   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    value_loss           | 3.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.6        |\n",
      "|    ep_rew_mean          | 1.37        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1580        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010865245 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.133      |\n",
      "|    explained_variance   | -0.00863    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.207       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    value_loss           | 2.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.5        |\n",
      "|    ep_rew_mean          | 0.872       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1578        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011619991 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.113      |\n",
      "|    explained_variance   | -0.00498    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00437     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 75.3         |\n",
      "|    ep_rew_mean          | 0.822        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062338067 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.135       |\n",
      "|    explained_variance   | -0.00753     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    value_loss           | 0.779        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.7        |\n",
      "|    ep_rew_mean          | 1.81        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1572        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021223992 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.089      |\n",
      "|    explained_variance   | -0.00472    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.522       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    value_loss           | 0.982       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.5        |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1572        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006731843 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0686     |\n",
      "|    explained_variance   | -0.00405    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 1.86        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71.9         |\n",
      "|    ep_rew_mean          | 0.617        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048592337 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0388      |\n",
      "|    explained_variance   | -0.0287      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0251       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    value_loss           | 0.267        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.1        |\n",
      "|    ep_rew_mean          | 1.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008001094 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0501     |\n",
      "|    explained_variance   | -0.0104     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.23        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    value_loss           | 0.368       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68.9         |\n",
      "|    ep_rew_mean          | 0.412        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072285994 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.053       |\n",
      "|    explained_variance   | -0.0088      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.538        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000544    |\n",
      "|    value_loss           | 0.9          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 73.8       |\n",
      "|    ep_rew_mean          | 0.576      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1564       |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01927754 |\n",
      "|    clip_fraction        | 0.0394     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0551    |\n",
      "|    explained_variance   | -0.0377    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.019     |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.00251   |\n",
      "|    value_loss           | 0.266      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.1        |\n",
      "|    ep_rew_mean          | 2.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1559        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008954354 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.115      |\n",
      "|    explained_variance   | -0.0041     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0242      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.000718   |\n",
      "|    value_loss           | 0.378       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.6        |\n",
      "|    ep_rew_mean          | 1.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1557        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014732204 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0874     |\n",
      "|    explained_variance   | -0.00166    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000115    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    value_loss           | 2.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.2        |\n",
      "|    ep_rew_mean          | 1.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1556        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016090123 |\n",
      "|    clip_fraction        | 0.026       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0607     |\n",
      "|    explained_variance   | -0.000557   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0039     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    value_loss           | 1.37        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 72.6         |\n",
      "|    ep_rew_mean          | 1.68         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1556         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046631214 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.056       |\n",
      "|    explained_variance   | -0.00271     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0132       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000991    |\n",
      "|    value_loss           | 1.66         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.8        |\n",
      "|    ep_rew_mean          | 0.566       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1556        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011253679 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0606     |\n",
      "|    explained_variance   | -0.00335    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.492       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.000557   |\n",
      "|    value_loss           | 1.77        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69.1         |\n",
      "|    ep_rew_mean          | 0.782        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1556         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033310594 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0365      |\n",
      "|    explained_variance   | -0.0101      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0224       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.000191    |\n",
      "|    value_loss           | 0.401        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 73.1         |\n",
      "|    ep_rew_mean          | 0.249        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1556         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071919067 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0437      |\n",
      "|    explained_variance   | -0.00157     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.403        |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000831    |\n",
      "|    value_loss           | 0.828        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.5        |\n",
      "|    ep_rew_mean          | 0.485       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1556        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015343629 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0928     |\n",
      "|    explained_variance   | -0.0329     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00124    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.7        |\n",
      "|    ep_rew_mean          | 0.699       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1556        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007418531 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0888     |\n",
      "|    explained_variance   | -0.0037     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0105      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.000882   |\n",
      "|    value_loss           | 0.321       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 66.7      |\n",
      "|    ep_rew_mean          | 0.641     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1556      |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 184       |\n",
      "|    total_timesteps      | 286720    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0162314 |\n",
      "|    clip_fraction        | 0.0353    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0558   |\n",
      "|    explained_variance   | -0.00396  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0461    |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -0.00193  |\n",
      "|    value_loss           | 0.835     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.9        |\n",
      "|    ep_rew_mean          | 1.85        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1556        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018256994 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0781     |\n",
      "|    explained_variance   | -0.0119     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.348       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    value_loss           | 0.437       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.7        |\n",
      "|    ep_rew_mean          | 0.828       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1554        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005246705 |\n",
      "|    clip_fraction        | 0.0379      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0885     |\n",
      "|    explained_variance   | -0.0036     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.491       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.000377   |\n",
      "|    value_loss           | 2.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.2        |\n",
      "|    ep_rew_mean          | 1.79        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1551        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011587443 |\n",
      "|    clip_fraction        | 0.0518      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.109      |\n",
      "|    explained_variance   | -0.0162     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    value_loss           | 0.874       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.5        |\n",
      "|    ep_rew_mean          | 0.133       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1545        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007675845 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.103      |\n",
      "|    explained_variance   | -0.00333    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.648       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    value_loss           | 1.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.9        |\n",
      "|    ep_rew_mean          | 1.72        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1544        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014614909 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0963     |\n",
      "|    explained_variance   | -0.0359     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.588       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70          |\n",
      "|    ep_rew_mean          | 0.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1543        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008988928 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0828     |\n",
      "|    explained_variance   | -0.00155    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0741      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.000797   |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68.5         |\n",
      "|    ep_rew_mean          | 0.47         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1542         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 344064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060781995 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0583      |\n",
      "|    explained_variance   | -0.000394    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.000885    |\n",
      "|    value_loss           | 2.06         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71.1         |\n",
      "|    ep_rew_mean          | 0.421        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1541         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 228          |\n",
      "|    total_timesteps      | 352256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074231084 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0508      |\n",
      "|    explained_variance   | -0.00157     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.178        |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    value_loss           | 1.44         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.7        |\n",
      "|    ep_rew_mean          | 0.734       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1541        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011678254 |\n",
      "|    clip_fraction        | 0.0337      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.038      |\n",
      "|    explained_variance   | -0.00518    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0566      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 73           |\n",
      "|    ep_rew_mean          | 1.37         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1540         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060690483 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0324      |\n",
      "|    explained_variance   | -0.00712     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.373        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.000867    |\n",
      "|    value_loss           | 0.401        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71.3         |\n",
      "|    ep_rew_mean          | 2.81         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1540         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 244          |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066222465 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.031       |\n",
      "|    explained_variance   | -0.00235     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0532       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.000617    |\n",
      "|    value_loss           | 1.44         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 75.5         |\n",
      "|    ep_rew_mean          | 0.676        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1540         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 249          |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030787205 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0356      |\n",
      "|    explained_variance   | -0.000142    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.596        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000468    |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.8        |\n",
      "|    ep_rew_mean          | 0.453       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1540        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009684128 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.037      |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0567      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 0.596       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.9        |\n",
      "|    ep_rew_mean          | 0.0297      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1539        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027022358 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.111      |\n",
      "|    explained_variance   | -0.0299     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0267     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    value_loss           | 0.244       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.1        |\n",
      "|    ep_rew_mean          | 1.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1539        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018353635 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.159      |\n",
      "|    explained_variance   | -0.000788   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0118     |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.6        |\n",
      "|    ep_rew_mean          | 0.692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1539        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009171177 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.142      |\n",
      "|    explained_variance   | -0.0019     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00173    |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 73.2         |\n",
      "|    ep_rew_mean          | 0.0531       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1538         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 276          |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108066425 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.123       |\n",
      "|    explained_variance   | -0.0325      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.283        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    value_loss           | 0.584        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.8        |\n",
      "|    ep_rew_mean          | 0.478       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1538        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016499333 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0932     |\n",
      "|    explained_variance   | -0.0506     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.286       |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 74.8         |\n",
      "|    ep_rew_mean          | 0.372        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1537         |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 287          |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043191025 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0823      |\n",
      "|    explained_variance   | -0.00418     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.453        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.000831    |\n",
      "|    value_loss           | 0.583        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 68.9       |\n",
      "|    ep_rew_mean          | 0.355      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1537       |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 292        |\n",
      "|    total_timesteps      | 450560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01024418 |\n",
      "|    clip_fraction        | 0.0521     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | -0.0124    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00486   |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.00316   |\n",
      "|    value_loss           | 0.332      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 73.7         |\n",
      "|    ep_rew_mean          | 0.313        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1538         |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 298          |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131974565 |\n",
      "|    clip_fraction        | 0.057        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0948      |\n",
      "|    explained_variance   | -0.0135      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0149       |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    value_loss           | 0.239        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 71.7       |\n",
      "|    ep_rew_mean          | 0.523      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1538       |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 303        |\n",
      "|    total_timesteps      | 466944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01388526 |\n",
      "|    clip_fraction        | 0.0525     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.109     |\n",
      "|    explained_variance   | -0.0353    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.631      |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.00393   |\n",
      "|    value_loss           | 0.344      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.7        |\n",
      "|    ep_rew_mean          | 0.441       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1539        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023928892 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.112      |\n",
      "|    explained_variance   | -0.00147    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00964     |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    value_loss           | 0.799       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 76.6         |\n",
      "|    ep_rew_mean          | 0.74         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1539         |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 313          |\n",
      "|    total_timesteps      | 483328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106141465 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0783      |\n",
      "|    explained_variance   | -0.0241      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.202        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 0.284        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.1        |\n",
      "|    ep_rew_mean          | 0.646       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1539        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008212452 |\n",
      "|    clip_fraction        | 0.033       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.07       |\n",
      "|    explained_variance   | -0.00345    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0167      |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    value_loss           | 0.486       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.4        |\n",
      "|    ep_rew_mean          | 0.825       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1540        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014805738 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0664     |\n",
      "|    explained_variance   | 0.0023      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    value_loss           | 0.533       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.3        |\n",
      "|    ep_rew_mean          | 0.52        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1540        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009438707 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0655     |\n",
      "|    explained_variance   | 0.00259     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0194      |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    value_loss           | 0.52        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.7        |\n",
      "|    ep_rew_mean          | 0.541       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1540        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007985656 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0506     |\n",
      "|    explained_variance   | -0.0096     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0007     |\n",
      "|    value_loss           | 0.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.2        |\n",
      "|    ep_rew_mean          | 0.968       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1540        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012024486 |\n",
      "|    clip_fraction        | 0.0412      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0749     |\n",
      "|    explained_variance   | -0.000149   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.164       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    value_loss           | 0.715       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 68.8       |\n",
      "|    ep_rew_mean          | 1.67       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1541       |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 345        |\n",
      "|    total_timesteps      | 532480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02310264 |\n",
      "|    clip_fraction        | 0.0451     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0871    |\n",
      "|    explained_variance   | -0.0104    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.21       |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.00134   |\n",
      "|    value_loss           | 1.26       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.7        |\n",
      "|    ep_rew_mean          | 0.86        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1541        |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013954006 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0863     |\n",
      "|    explained_variance   | -0.0126     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.268       |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.5        |\n",
      "|    ep_rew_mean          | 1.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1540        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 356         |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012241054 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0924     |\n",
      "|    explained_variance   | -0.00972    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0869      |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    value_loss           | 0.812       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 70           |\n",
      "|    ep_rew_mean          | 2.12         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1540         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 361          |\n",
      "|    total_timesteps      | 557056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058124103 |\n",
      "|    clip_fraction        | 0.0464       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0933      |\n",
      "|    explained_variance   | -0.00167     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    value_loss           | 2.35         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 72.3       |\n",
      "|    ep_rew_mean          | 0.667      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1540       |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 366        |\n",
      "|    total_timesteps      | 565248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01097828 |\n",
      "|    clip_fraction        | 0.0557     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | -0.0117    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.295      |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.00191   |\n",
      "|    value_loss           | 2.14       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.7        |\n",
      "|    ep_rew_mean          | 0.285       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1540        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008825339 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.119      |\n",
      "|    explained_variance   | -0.0187     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.455       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00102    |\n",
      "|    value_loss           | 0.739       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.3        |\n",
      "|    ep_rew_mean          | 0.734       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1539        |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 377         |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009049892 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0957     |\n",
      "|    explained_variance   | -0.043      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0111     |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69          |\n",
      "|    ep_rew_mean          | 0.808       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1539        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014213318 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0858     |\n",
      "|    explained_variance   | -0.000162   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    value_loss           | 0.712       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.7        |\n",
      "|    ep_rew_mean          | 0.789       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1539        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 388         |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017334575 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.132      |\n",
      "|    explained_variance   | -0.0275     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00533    |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 0.582       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.9        |\n",
      "|    ep_rew_mean          | 1.91        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1538        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 393         |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013407402 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.152      |\n",
      "|    explained_variance   | 0.00534     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.702       |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 0.744       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.4        |\n",
      "|    ep_rew_mean          | 0.571       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1538        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 399         |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010665382 |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.121      |\n",
      "|    explained_variance   | -0.00767    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.542       |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    value_loss           | 1.94        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.3        |\n",
      "|    ep_rew_mean          | 1.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1538        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012409202 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.111      |\n",
      "|    explained_variance   | -0.00573    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.37        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    value_loss           | 0.543       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.6        |\n",
      "|    ep_rew_mean          | 0.487       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1537        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013491959 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.127      |\n",
      "|    explained_variance   | -0.00572    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00194     |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    value_loss           | 1.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.5        |\n",
      "|    ep_rew_mean          | 0.533       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1536        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015687305 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.115      |\n",
      "|    explained_variance   | -0.013      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00398    |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    value_loss           | 0.412       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.6        |\n",
      "|    ep_rew_mean          | 1.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1536        |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009272193 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.101      |\n",
      "|    explained_variance   | -0.00469    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.613       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    value_loss           | 0.613       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73          |\n",
      "|    ep_rew_mean          | 0.437       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1536        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 426         |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014211493 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0915     |\n",
      "|    explained_variance   | -0.00506    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.519       |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.5        |\n",
      "|    ep_rew_mean          | 1.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013563995 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.109      |\n",
      "|    explained_variance   | -0.00159    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.606       |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00016    |\n",
      "|    value_loss           | 0.498       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66          |\n",
      "|    ep_rew_mean          | 1.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010771699 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.11       |\n",
      "|    explained_variance   | -0.00444    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00924    |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.4        |\n",
      "|    ep_rew_mean          | 1.62        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1534        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016005367 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.148      |\n",
      "|    explained_variance   | -0.00256    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0175     |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 65.6       |\n",
      "|    ep_rew_mean          | 0.525      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1533       |\n",
      "|    iterations           | 84         |\n",
      "|    time_elapsed         | 448        |\n",
      "|    total_timesteps      | 688128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01580163 |\n",
      "|    clip_fraction        | 0.0886     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.197     |\n",
      "|    explained_variance   | -0.00175   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0278     |\n",
      "|    n_updates            | 830        |\n",
      "|    policy_gradient_loss | -0.00446   |\n",
      "|    value_loss           | 2.02       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.6        |\n",
      "|    ep_rew_mean          | 0.659       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1532        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023055747 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.194      |\n",
      "|    explained_variance   | -0.0286     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0438      |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    value_loss           | 0.309       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 68.2       |\n",
      "|    ep_rew_mean          | 1.32       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1531       |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 459        |\n",
      "|    total_timesteps      | 704512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01282107 |\n",
      "|    clip_fraction        | 0.0662     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.176     |\n",
      "|    explained_variance   | -0.00556   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.138      |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | -0.00319   |\n",
      "|    value_loss           | 0.59       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.3        |\n",
      "|    ep_rew_mean          | 0.135       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1532        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 465         |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016826682 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.156      |\n",
      "|    explained_variance   | 0.00163     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    value_loss           | 1.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.9        |\n",
      "|    ep_rew_mean          | 0.939       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1532        |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014425467 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.164      |\n",
      "|    explained_variance   | -0.0228     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0421      |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 70           |\n",
      "|    ep_rew_mean          | 0.271        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1533         |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 475          |\n",
      "|    total_timesteps      | 729088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099841785 |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.188       |\n",
      "|    explained_variance   | -0.0131      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.438        |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 1.07         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.8        |\n",
      "|    ep_rew_mean          | 0.235       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1533        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038178273 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.24       |\n",
      "|    explained_variance   | -0.0664     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00367     |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    value_loss           | 0.244       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.9        |\n",
      "|    ep_rew_mean          | 0.567       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1533        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 486         |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012058223 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | -0.000694   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69          |\n",
      "|    ep_rew_mean          | 1.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1534        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010428906 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.189      |\n",
      "|    explained_variance   | -0.0147     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.756       |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 0.464       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.5        |\n",
      "|    ep_rew_mean          | 0.601       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1534        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010449704 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.174      |\n",
      "|    explained_variance   | 0.000199    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.317       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.1        |\n",
      "|    ep_rew_mean          | 0.655       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1534        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009361788 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.167      |\n",
      "|    explained_variance   | -0.00602    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.333       |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    value_loss           | 0.581       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.7        |\n",
      "|    ep_rew_mean          | 0.00692     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1534        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 507         |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023237467 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.166      |\n",
      "|    explained_variance   | -0.00899    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.464       |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    value_loss           | 0.457       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70          |\n",
      "|    ep_rew_mean          | 0.239       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 512         |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015088796 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.17       |\n",
      "|    explained_variance   | -0.0382     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0117     |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    value_loss           | 0.0814      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.9        |\n",
      "|    ep_rew_mean          | 1.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 517         |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013762071 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.155      |\n",
      "|    explained_variance   | -0.0132     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0267     |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.6        |\n",
      "|    ep_rew_mean          | 0.416       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 522         |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008585221 |\n",
      "|    clip_fraction        | 0.0467      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.125      |\n",
      "|    explained_variance   | 0.000293    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00181     |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.5        |\n",
      "|    ep_rew_mean          | 0.407       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020501446 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.123      |\n",
      "|    explained_variance   | -0.0165     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0157     |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    value_loss           | 0.333       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.6        |\n",
      "|    ep_rew_mean          | 1.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 533         |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014696452 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.164      |\n",
      "|    explained_variance   | -0.00482    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.361       |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | 8.96e-05    |\n",
      "|    value_loss           | 0.456       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.9        |\n",
      "|    ep_rew_mean          | 0.616       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 538         |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009093823 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.159      |\n",
      "|    explained_variance   | -0.00113    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.021      |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    value_loss           | 1.63        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 70.1        |\n",
      "|    ep_rew_mean          | 1.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 544         |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008345605 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.154      |\n",
      "|    explained_variance   | 0.00252     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    value_loss           | 0.372       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 72.1       |\n",
      "|    ep_rew_mean          | 0.356      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1535       |\n",
      "|    iterations           | 103        |\n",
      "|    time_elapsed         | 549        |\n",
      "|    total_timesteps      | 843776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01411604 |\n",
      "|    clip_fraction        | 0.0632     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.112     |\n",
      "|    explained_variance   | -0.00186   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0139    |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | -0.00524   |\n",
      "|    value_loss           | 1.83       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.2        |\n",
      "|    ep_rew_mean          | 2.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 554         |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013331696 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.151      |\n",
      "|    explained_variance   | -0.00962    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    value_loss           | 0.362       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.4        |\n",
      "|    ep_rew_mean          | 1.37        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 560         |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012622718 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.133      |\n",
      "|    explained_variance   | -0.000473   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 3.69        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.7        |\n",
      "|    ep_rew_mean          | 2.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043896794 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.148      |\n",
      "|    explained_variance   | -0.00543    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0482      |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    value_loss           | 1.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.9        |\n",
      "|    ep_rew_mean          | 0.245       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013903879 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.166      |\n",
      "|    explained_variance   | -0.00134    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0364      |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.6        |\n",
      "|    ep_rew_mean          | 0.808       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 576         |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010082774 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.148      |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0204      |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 71.4      |\n",
      "|    ep_rew_mean          | 0.398     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1536      |\n",
      "|    iterations           | 109       |\n",
      "|    time_elapsed         | 581       |\n",
      "|    total_timesteps      | 892928    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0088094 |\n",
      "|    clip_fraction        | 0.0529    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.139    |\n",
      "|    explained_variance   | -0.000147 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00696   |\n",
      "|    n_updates            | 1080      |\n",
      "|    policy_gradient_loss | -0.00201  |\n",
      "|    value_loss           | 1.12      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.6        |\n",
      "|    ep_rew_mean          | 0.677       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1536        |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014222018 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.136      |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0199      |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    value_loss           | 0.387       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.6        |\n",
      "|    ep_rew_mean          | 0.739       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1536        |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 591         |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006884519 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.12       |\n",
      "|    explained_variance   | -0.00201    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0213      |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.000798   |\n",
      "|    value_loss           | 0.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.5        |\n",
      "|    ep_rew_mean          | 0.364       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1536        |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011957709 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0838     |\n",
      "|    explained_variance   | -0.0102     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.349       |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    value_loss           | 0.695       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.8        |\n",
      "|    ep_rew_mean          | 0.134       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1537        |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 602         |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019762978 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.105      |\n",
      "|    explained_variance   | -0.038      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.498       |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.6        |\n",
      "|    ep_rew_mean          | 0.319       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1537        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 607         |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015146455 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.14       |\n",
      "|    explained_variance   | -0.0109     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00403    |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.3        |\n",
      "|    ep_rew_mean          | 1.68        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1537        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012632294 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.126      |\n",
      "|    explained_variance   | -0.00444    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.275       |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    value_loss           | 0.267       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.7        |\n",
      "|    ep_rew_mean          | 0.545       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1537        |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 618         |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014303981 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0746     |\n",
      "|    explained_variance   | -0.00379    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0999      |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    value_loss           | 1.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.1        |\n",
      "|    ep_rew_mean          | 1.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1537        |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009587771 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0671     |\n",
      "|    explained_variance   | -0.00222    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0801      |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    value_loss           | 0.451       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.8        |\n",
      "|    ep_rew_mean          | 1.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1537        |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 628         |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009192584 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0703     |\n",
      "|    explained_variance   | -0.00162    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.374       |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    value_loss           | 1.56        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68.9         |\n",
      "|    ep_rew_mean          | 1.67         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1537         |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 633          |\n",
      "|    total_timesteps      | 974848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125020575 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0769      |\n",
      "|    explained_variance   | -0.00158     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0177      |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.61         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.7        |\n",
      "|    ep_rew_mean          | 0.661       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1538        |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 639         |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009545604 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0954     |\n",
      "|    explained_variance   | -0.00273    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 1.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 72.5        |\n",
      "|    ep_rew_mean          | 0.314       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1538        |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 644         |\n",
      "|    total_timesteps      | 991232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014077192 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.103      |\n",
      "|    explained_variance   | -0.0117     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 0.588       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 64.3        |\n",
      "|    ep_rew_mean          | 1.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1538        |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 649         |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012093797 |\n",
      "|    clip_fraction        | 0.0455      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0845     |\n",
      "|    explained_variance   | -0.0086     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000112   |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    value_loss           | 0.536       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.1        |\n",
      "|    ep_rew_mean          | 0.346       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1538        |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008487064 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0705     |\n",
      "|    explained_variance   | -0.000286   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.672       |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00121    |\n",
      "|    value_loss           | 1.22        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x14e4e3670>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the PPO model\n",
    "model3 = PPO(\"MlpPolicy\", env_vec_four2, verbose=1,\n",
    "            tensorboard_log=\"log/ppo_reward_four_no_step_cap\"\n",
    "            )\n",
    "\n",
    "# Train the model\n",
    "model3.learn(total_timesteps=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save(\"models/ppo_reward_four_no_step_cap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward: 1.88698806 +/- 4.938896124777096\n"
     ]
    }
   ],
   "source": [
    "model3 = PPO.load(\"models/ppo_reward_four_no_step_cap\",env=env_vec_four)\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model3, env=env_vec_four, n_eval_episodes=50)\n",
    "print(f\"Mean Reward: {mean_reward} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = [0.07432037]\n",
      "Episode 2: Total Reward = [-0.28315964]\n",
      "Episode 3: Total Reward = [-0.09541319]\n",
      "Episode 4: Total Reward = [-0.20858501]\n",
      "Episode 5: Total Reward = [-0.38462046]\n",
      "Episode 6: Total Reward = [-0.3333732]\n",
      "Episode 7: Total Reward = [-0.37874836]\n",
      "Episode 8: Total Reward = [-0.25044495]\n",
      "Episode 9: Total Reward = [0.10625922]\n",
      "Episode 10: Total Reward = [0.7834232]\n",
      "Episode 11: Total Reward = [-0.18577224]\n",
      "Episode 12: Total Reward = [-0.34283423]\n",
      "Episode 13: Total Reward = [0.02092703]\n",
      "Episode 14: Total Reward = [-0.44554368]\n",
      "Episode 15: Total Reward = [0.47696018]\n",
      "Episode 16: Total Reward = [-0.17119548]\n",
      "Episode 17: Total Reward = [-0.48476073]\n",
      "Episode 18: Total Reward = [0.18649572]\n",
      "Episode 19: Total Reward = [0.01933805]\n",
      "Episode 20: Total Reward = [-0.32086325]\n",
      "Episode 21: Total Reward = [-0.0723269]\n",
      "Episode 22: Total Reward = [-0.34727725]\n",
      "Episode 23: Total Reward = [-0.07864127]\n",
      "Episode 24: Total Reward = [0.4175687]\n",
      "Episode 25: Total Reward = [0.03316989]\n",
      "Episode 26: Total Reward = [0.14699699]\n",
      "Episode 27: Total Reward = [0.88148445]\n",
      "Episode 28: Total Reward = [0.7262043]\n",
      "Episode 29: Total Reward = [5.148483]\n",
      "Episode 30: Total Reward = [-0.02398337]\n",
      "Episode 31: Total Reward = [0.48535538]\n",
      "Episode 32: Total Reward = [-0.03506179]\n",
      "Episode 33: Total Reward = [-0.10125652]\n",
      "Episode 34: Total Reward = [-0.2962795]\n",
      "Episode 35: Total Reward = [-0.15630019]\n",
      "Episode 36: Total Reward = [-0.25390026]\n",
      "Episode 37: Total Reward = [0.8795891]\n",
      "Episode 38: Total Reward = [0.41366622]\n",
      "Episode 39: Total Reward = [0.8294151]\n",
      "Episode 40: Total Reward = [-0.17169452]\n",
      "Episode 41: Total Reward = [-0.34447852]\n",
      "Episode 42: Total Reward = [0.05895364]\n",
      "Episode 43: Total Reward = [0.914]\n",
      "Episode 44: Total Reward = [-0.23743626]\n",
      "Episode 45: Total Reward = [-0.25033653]\n",
      "Episode 46: Total Reward = [-0.11809333]\n",
      "Episode 47: Total Reward = [0.19817667]\n",
      "Episode 48: Total Reward = [-0.07632345]\n",
      "Episode 49: Total Reward = [-0.08377834]\n",
      "Episode 50: Total Reward = [-0.08127684]\n",
      "Average Reward over 50 episodes: [0.12374055]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "total_rewards = []  # List to store total rewards for each episode\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs = env_vec_four.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model3.predict(obs)\n",
    "        obs, reward, done, info = env_vec_four.step(action)\n",
    "        #print(done)\n",
    "        total_reward += reward\n",
    "        env_vec_four.render('human')  # Render the environment at each step\n",
    "        #time.sleep(0.05)  # Adjust this to control the speed of the rendering\n",
    "    total_rewards.append(total_reward)  # Store the total reward for this episode\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "# Calculate the average reward across all episodes\n",
    "average_reward = sum(total_rewards) / num_episodes\n",
    "print(f\"Average Reward over {num_episodes} episodes: {average_reward}\")\n",
    "\n",
    "env_vec_four.close()  # Close the environment when done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
